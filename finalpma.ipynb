{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import the necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poster_url</th>\n",
       "      <th>rt_audience_score</th>\n",
       "      <th>rt_freshness</th>\n",
       "      <th>2015_inflation</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>genres</th>\n",
       "      <th>Genre_1</th>\n",
       "      <th>Genre_2</th>\n",
       "      <th>Genre_3</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>length</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>studio</th>\n",
       "      <th>title</th>\n",
       "      <th>worldwide_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://resizing.flixster.com/gxRJwetP1eNIrPR6x...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>$712,903,691.09</td>\n",
       "      <td>Sci-Fi\\nAdventure\\nAction</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Action</td>\n",
       "      <td>7.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>04-Apr-14</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Captain America: The Winter Soldier</td>\n",
       "      <td>$714,766,572.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://resizing.flixster.com/gDtbA1iPxTYEjBZeS...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>$706,988,165.89</td>\n",
       "      <td>Sci-Fi\\nDrama\\nAction</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Action</td>\n",
       "      <td>7.7</td>\n",
       "      <td>130.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>11-Jul-14</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>Dawn of the Planet of the Apes</td>\n",
       "      <td>$708,835,589.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://resizing.flixster.com/YrF_OeTQx3bXNsMLI...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>$772,158,880.00</td>\n",
       "      <td>Sci-Fi\\nAdventure\\nAction</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Action</td>\n",
       "      <td>8.1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>01-Aug-14</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>$774,176,600.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://resizing.flixster.com/l9yjA-72sZMYECeOj...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>$671,220,455.10</td>\n",
       "      <td>Sci-Fi\\nAdventure</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>169.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>07-Nov-14</td>\n",
       "      <td>Paramount Pictures / Warner Bros.</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>$672,974,414.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://resizing.flixster.com/YukULOFULUesVZccN...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.26%</td>\n",
       "      <td>$756,677,675.77</td>\n",
       "      <td>Family\\nAdventure\\nAction</td>\n",
       "      <td>Family</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Action</td>\n",
       "      <td>7.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>30-May-14</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "      <td>Maleficent</td>\n",
       "      <td>$758,654,942.00</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          poster_url  rt_audience_score  \\\n",
       "0  http://resizing.flixster.com/gxRJwetP1eNIrPR6x...                4.3   \n",
       "1  http://resizing.flixster.com/gDtbA1iPxTYEjBZeS...                4.2   \n",
       "2  http://resizing.flixster.com/YrF_OeTQx3bXNsMLI...                4.4   \n",
       "3  http://resizing.flixster.com/l9yjA-72sZMYECeOj...                4.2   \n",
       "4  http://resizing.flixster.com/YukULOFULUesVZccN...                3.8   \n",
       "\n",
       "   rt_freshness 2015_inflation          adjusted                     genres  \\\n",
       "0          89.0         -0.26%  $712,903,691.09   Sci-Fi\\nAdventure\\nAction   \n",
       "1          90.0         -0.26%  $706,988,165.89       Sci-Fi\\nDrama\\nAction   \n",
       "2          91.0         -0.26%  $772,158,880.00   Sci-Fi\\nAdventure\\nAction   \n",
       "3          72.0         -0.26%  $671,220,455.10           Sci-Fi\\nAdventure   \n",
       "4          49.0         -0.26%  $756,677,675.77   Family\\nAdventure\\nAction   \n",
       "\n",
       "  Genre_1    Genre_2 Genre_3  imdb_rating  length rating release_date  \\\n",
       "0  Sci-Fi  Adventure  Action          7.8   136.0  PG-13    04-Apr-14   \n",
       "1  Sci-Fi      Drama  Action          7.7   130.0  PG-13    11-Jul-14   \n",
       "2  Sci-Fi  Adventure  Action          8.1   121.0  PG-13    01-Aug-14   \n",
       "3  Sci-Fi  Adventure     NaN          8.7   169.0  PG-13    07-Nov-14   \n",
       "4  Family  Adventure  Action          7.1    97.0     PG    30-May-14   \n",
       "\n",
       "                              studio                                title  \\\n",
       "0                     Marvel Studios  Captain America: The Winter Soldier   \n",
       "1                   20th Century Fox       Dawn of the Planet of the Apes   \n",
       "2                     Marvel Studios              Guardians of the Galaxy   \n",
       "3  Paramount Pictures / Warner Bros.                         Interstellar   \n",
       "4               Walt Disney Pictures                           Maleficent   \n",
       "\n",
       "    worldwide_gross    year  \n",
       "0  $714,766,572.00   2014.0  \n",
       "1  $708,835,589.00   2014.0  \n",
       "2  $774,176,600.00   2014.0  \n",
       "3  $672,974,414.00   2014.0  \n",
       "4  $758,654,942.00   2014.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"PMA_blockbuster_movies.csv\")\n",
    "movies.head()\n",
    "# read the data into python by pandas\n",
    "# show some details of the datases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop([\"poster_url\",\"2015_inflation\",\"release_date\",\"title\",\"worldwide_gross\",\"year\",\"studio\"],axis =1)\n",
    "# drop some useless features. \n",
    "# since the box office has been adjusted, 2015_inflation and worldwide_gross is not necessary in the prediction. the data in 2015_inflation mutiply the data in word_gross is the data in adjusted field.\n",
    "# since good film will not be effected by time, yaer is deleted\n",
    "# poster_url, title and release_date are not related so drop them.\n",
    "# studio may affect the box office like marvel and universal, but we do not consider it in this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.dropna(subset=[\"adjusted\"])\n",
    "# delete the missing value in Dependent variable column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop([\"genres\",\"Genre_2\",\"Genre_3\"],axis=1)\n",
    "# choose the main type of movie as a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt_audience_score    0\n",
      "rt_freshness         0\n",
      "adjusted             0\n",
      "Genre_1              0\n",
      "imdb_rating          0\n",
      "length               0\n",
      "rating               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) \n",
    "missing_values_count = movies.isnull().sum()\n",
    "print(missing_values_count)\n",
    "# through counting missing value, it is interseting to note that there is no missing value\n",
    "# then the next step is using get_dummies idea to clean the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genre = pd.get_dummies(movies[\"Genre_1\"],prefix='genre')\n",
    "# use get_dummies to process the genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rating = pd.get_dummies(movies[\"rating\"],prefix='rating')\n",
    "# use get_dummies to process the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.concat([movies.drop([\"Genre_1\",\"rating\"], axis=1),movies_genre,movies_rating], axis=1)\n",
    "# merge all the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['adjusted'] = movies['adjusted'].str.replace(',', '')\n",
    "movies['adjusted'] = movies['adjusted'].str.replace('$', '')\n",
    "movies['adjusted'] = movies['adjusted'].astype(float)\n",
    "# convert box office's type into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt_audience_score</th>\n",
       "      <th>rt_freshness</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>length</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Animation</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Sci-Fi</th>\n",
       "      <th>genre_Sport</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_War</th>\n",
       "      <th>genre_Western</th>\n",
       "      <th>rating_G</th>\n",
       "      <th>rating_PG</th>\n",
       "      <th>rating_PG-13</th>\n",
       "      <th>rating_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>7.129037e+08</td>\n",
       "      <td>7.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.069882e+08</td>\n",
       "      <td>7.7</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.721589e+08</td>\n",
       "      <td>8.1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.712205e+08</td>\n",
       "      <td>8.7</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.566777e+08</td>\n",
       "      <td>7.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rt_audience_score  rt_freshness      adjusted  imdb_rating  length  \\\n",
       "0                4.3          89.0  7.129037e+08          7.8   136.0   \n",
       "1                4.2          90.0  7.069882e+08          7.7   130.0   \n",
       "2                4.4          91.0  7.721589e+08          8.1   121.0   \n",
       "3                4.2          72.0  6.712205e+08          8.7   169.0   \n",
       "4                3.8          49.0  7.566777e+08          7.1    97.0   \n",
       "\n",
       "   genre_Action  genre_Adventure  genre_Animation  genre_Comedy  genre_Crime  \\\n",
       "0             0                0                0             0            0   \n",
       "1             0                0                0             0            0   \n",
       "2             0                0                0             0            0   \n",
       "3             0                0                0             0            0   \n",
       "4             0                0                0             0            0   \n",
       "\n",
       "   ...  genre_Romance  genre_Sci-Fi  genre_Sport  genre_Thriller  genre_War  \\\n",
       "0  ...              0             1            0               0          0   \n",
       "1  ...              0             1            0               0          0   \n",
       "2  ...              0             1            0               0          0   \n",
       "3  ...              0             1            0               0          0   \n",
       "4  ...              0             0            0               0          0   \n",
       "\n",
       "   genre_Western  rating_G  rating_PG  rating_PG-13  rating_R  \n",
       "0              0         0          0             1         0  \n",
       "1              0         0          0             1         0  \n",
       "2              0         0          0             1         0  \n",
       "3              0         0          0             1         0  \n",
       "4              0         0          1             0         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()\n",
    "# all cleaning steps and feature engineering steps are done, the next step will be separating the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt_audience_score</th>\n",
       "      <th>rt_freshness</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>length</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Animation</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Sci-Fi</th>\n",
       "      <th>genre_Sport</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_War</th>\n",
       "      <th>genre_Western</th>\n",
       "      <th>rating_G</th>\n",
       "      <th>rating_PG</th>\n",
       "      <th>rating_PG-13</th>\n",
       "      <th>rating_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>3.980000e+02</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.478894</td>\n",
       "      <td>69.381910</td>\n",
       "      <td>5.428198e+08</td>\n",
       "      <td>7.053266</td>\n",
       "      <td>119.253769</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.135678</td>\n",
       "      <td>0.042714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118090</td>\n",
       "      <td>0.123116</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.138191</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.065327</td>\n",
       "      <td>0.319095</td>\n",
       "      <td>0.369347</td>\n",
       "      <td>0.246231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.391222</td>\n",
       "      <td>23.186895</td>\n",
       "      <td>3.407107e+08</td>\n",
       "      <td>0.834777</td>\n",
       "      <td>22.973721</td>\n",
       "      <td>0.086601</td>\n",
       "      <td>0.177978</td>\n",
       "      <td>0.122006</td>\n",
       "      <td>0.342878</td>\n",
       "      <td>0.202465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323121</td>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.131614</td>\n",
       "      <td>0.345535</td>\n",
       "      <td>0.156704</td>\n",
       "      <td>0.086601</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.466713</td>\n",
       "      <td>0.483235</td>\n",
       "      <td>0.431357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100475e+08</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.936418e+08</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>102.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>4.880479e+08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>6.985807e+08</td>\n",
       "      <td>7.675000</td>\n",
       "      <td>131.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.025615e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rt_audience_score  rt_freshness      adjusted  imdb_rating      length  \\\n",
       "count         398.000000    398.000000  3.980000e+02   398.000000  398.000000   \n",
       "mean            3.478894     69.381910  5.428198e+08     7.053266  119.253769   \n",
       "std             0.391222     23.186895  3.407107e+08     0.834777   22.973721   \n",
       "min             1.700000      0.000000  1.100475e+08     4.400000   27.000000   \n",
       "25%             3.200000     54.000000  2.936418e+08     6.500000  102.250000   \n",
       "50%             3.500000     75.500000  4.880479e+08     7.000000  117.000000   \n",
       "75%             3.700000     88.000000  6.985807e+08     7.675000  131.750000   \n",
       "max             4.500000    100.000000  3.025615e+09     9.000000  201.000000   \n",
       "\n",
       "       genre_Action  genre_Adventure  genre_Animation  genre_Comedy  \\\n",
       "count    398.000000       398.000000       398.000000    398.000000   \n",
       "mean       0.007538         0.032663         0.015075      0.135678   \n",
       "std        0.086601         0.177978         0.122006      0.342878   \n",
       "min        0.000000         0.000000         0.000000      0.000000   \n",
       "25%        0.000000         0.000000         0.000000      0.000000   \n",
       "50%        0.000000         0.000000         0.000000      0.000000   \n",
       "75%        0.000000         0.000000         0.000000      0.000000   \n",
       "max        1.000000         1.000000         1.000000      1.000000   \n",
       "\n",
       "       genre_Crime  ...  genre_Romance  genre_Sci-Fi  genre_Sport  \\\n",
       "count   398.000000  ...     398.000000    398.000000   398.000000   \n",
       "mean      0.042714  ...       0.118090      0.123116     0.017588   \n",
       "std       0.202465  ...       0.323121      0.328983     0.131614   \n",
       "min       0.000000  ...       0.000000      0.000000     0.000000   \n",
       "25%       0.000000  ...       0.000000      0.000000     0.000000   \n",
       "50%       0.000000  ...       0.000000      0.000000     0.000000   \n",
       "75%       0.000000  ...       0.000000      0.000000     0.000000   \n",
       "max       1.000000  ...       1.000000      1.000000     1.000000   \n",
       "\n",
       "       genre_Thriller   genre_War  genre_Western    rating_G   rating_PG  \\\n",
       "count      398.000000  398.000000     398.000000  398.000000  398.000000   \n",
       "mean         0.138191    0.025126       0.007538    0.065327    0.319095   \n",
       "std          0.345535    0.156704       0.086601    0.247412    0.466713   \n",
       "min          0.000000    0.000000       0.000000    0.000000    0.000000   \n",
       "25%          0.000000    0.000000       0.000000    0.000000    0.000000   \n",
       "50%          0.000000    0.000000       0.000000    0.000000    0.000000   \n",
       "75%          0.000000    0.000000       0.000000    0.000000    1.000000   \n",
       "max          1.000000    1.000000       1.000000    1.000000    1.000000   \n",
       "\n",
       "       rating_PG-13    rating_R  \n",
       "count    398.000000  398.000000  \n",
       "mean       0.369347    0.246231  \n",
       "std        0.483235    0.431357  \n",
       "min        0.000000    0.000000  \n",
       "25%        0.000000    0.000000  \n",
       "50%        0.000000    0.000000  \n",
       "75%        1.000000    0.000000  \n",
       "max        1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be seen from the dataset that all the box office are higher than $100000000, which means nearly all the sample is successful in box office\n",
    "# I decide to see it as a classification issue, and use oversampling to sampling.\n",
    "# SVR,XGBoosting and GBDT are used in the prediction. Finally,voting classifier will be used in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_adjusted = movies[\"adjusted\"]\n",
    "movies_adjusted = pd.DataFrame(movies_adjusted)\n",
    "movies_adjusted[movies_adjusted[\"adjusted\"]<200000000] = 0\n",
    "movies_adjusted[movies_adjusted[\"adjusted\"]>200000000] = 1\n",
    "movies = pd.concat([movies.drop([\"adjusted\"],axis =1),movies_adjusted], axis =1)\n",
    "# set adjusted = 200000000 as the threshold, Set the predicted data to 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549, 27)\n",
      "(549,)\n",
      "(138, 27)\n",
      "(138,)\n"
     ]
    }
   ],
   "source": [
    "y_data = movies[\"adjusted\"]\n",
    "x_data = movies.drop([\"adjusted\"], axis=1)\n",
    "from imblearn.over_sampling import ADASYN\n",
    "ada = ADASYN(random_state=42,sampling_strategy='minority', n_neighbors=5, n_jobs=1)\n",
    "x_data, y_data = ada.fit_resample(x_data, y_data)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "# split the data into train and test data\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyperparameters for accuracy\n",
      "\n",
      "\n",
      "Best parameters set found on the training set:\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "# Tuning hyperparameters for f1_macro\n",
      "\n",
      "\n",
      "Best parameters set found on the training set:\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the first is SVC\n",
    "# tunning the hyperparameters and use r2 score and mean_squared_error to evaluate the results\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters =  [{'kernel': ['rbf'], 'gamma': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 100],'gamma': [100, 10, 1, 1e-1, 1e-2, 1e-3, 1e-4]}]\n",
    "\n",
    "scores = [\"accuracy\",\"f1_macro\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.9381\n",
      "Accuracy score = 0.8913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.89        70\n",
      "         1.0       0.85      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.89       138\n",
      "   macro avg       0.89      0.89      0.89       138\n",
      "weighted avg       0.90      0.89      0.89       138\n",
      "\n",
      "[[59 11]\n",
      " [ 4 64]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# use the tuning hyperparameters to build the final model\n",
    "svm = SVC(C = 1, kernel = \"rbf\", gamma = 0.1 )\n",
    "# fit the model using some training data\n",
    "svm_fit = svm.fit(x_train, y_train)\n",
    "# generate a mean accuracy score for the predicted data\n",
    "train_score = svm.score(x_train, y_train)\n",
    "\n",
    "# print the mean accuracy of testing predictions\n",
    "print(\"Accuracy score = \" + str(round(train_score, 4)))\n",
    "\n",
    "# predict the test data\n",
    "predicted = svm.predict(x_test)\n",
    "\n",
    "# generate a mean accuracy score for the predicted data\n",
    "test_score = svm.score(x_test, y_test)\n",
    "\n",
    "# print the mean accuracy of testing predictions\n",
    "print(\"Accuracy score = \" + str(round(test_score, 4)))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "# scource: moodle warwick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.22231178, 0.21722474, 0.19127755, 0.23636203, 0.15822716,\n",
       "         0.14671378, 0.21446061, 0.19998541, 0.20703673, 0.10757976,\n",
       "         0.15616736, 0.21011367, 0.21326823, 0.13553987, 0.16087298,\n",
       "         0.21219711, 0.13716497, 0.16150374, 0.18997931, 0.18799124,\n",
       "         0.13994212, 0.22746201, 0.13818407, 0.21480341, 0.15768523,\n",
       "         0.2220983 , 0.19129643, 0.12719707, 0.22036877, 0.24450436,\n",
       "         0.14530015, 0.25235462, 0.14661026, 0.28045287, 0.26559076,\n",
       "         0.22335196, 0.18625078, 0.22205825, 0.19191132, 0.16629524]),\n",
       "  'std_fit_time': array([0.1210614 , 0.10471801, 0.07112361, 0.09996822, 0.04830525,\n",
       "         0.04183608, 0.1603343 , 0.16067102, 0.19896685, 0.01568447,\n",
       "         0.04789325, 0.06830734, 0.16137114, 0.03634789, 0.06868215,\n",
       "         0.14350233, 0.04334482, 0.05661549, 0.10919914, 0.05655372,\n",
       "         0.02717555, 0.13473994, 0.05292796, 0.09710718, 0.08276278,\n",
       "         0.18551764, 0.05307404, 0.0161249 , 0.12812415, 0.22711793,\n",
       "         0.02642826, 0.18019625, 0.07131262, 0.12219527, 0.12975098,\n",
       "         0.10556198, 0.03571939, 0.09523712, 0.08434106, 0.03279564]),\n",
       "  'mean_score_time': array([0.00359869, 0.0025538 , 0.00263362, 0.00278134, 0.0024251 ,\n",
       "         0.00307784, 0.00249562, 0.00247874, 0.00254169, 0.00257683,\n",
       "         0.00268173, 0.0024735 , 0.00255899, 0.00283937, 0.00245938,\n",
       "         0.00440884, 0.00242562, 0.00260258, 0.00267143, 0.00251107,\n",
       "         0.00406432, 0.00253019, 0.00241017, 0.00269003, 0.00262976,\n",
       "         0.00263028, 0.00434551, 0.00292168, 0.0027812 , 0.00265999,\n",
       "         0.00286574, 0.00288057, 0.0029233 , 0.00280657, 0.00298066,\n",
       "         0.00273027, 0.00300884, 0.0031713 , 0.00316911, 0.00296569]),\n",
       "  'std_score_time': array([1.32535617e-03, 2.19283437e-04, 3.26558661e-04, 4.73795785e-04,\n",
       "         1.33001210e-04, 1.14770550e-03, 2.84382899e-05, 1.77202183e-04,\n",
       "         2.17982371e-04, 3.20240016e-04, 4.15036855e-04, 1.21915391e-04,\n",
       "         1.95765982e-04, 5.04514071e-04, 8.30380936e-05, 3.92398903e-03,\n",
       "         1.21941946e-04, 2.50638420e-04, 2.45529162e-04, 1.92987868e-04,\n",
       "         3.20416236e-03, 1.89868545e-04, 1.19671118e-04, 6.10011487e-04,\n",
       "         2.19490791e-04, 1.26664806e-04, 3.39753221e-03, 2.00353594e-04,\n",
       "         1.43717754e-04, 1.06549623e-04, 2.58985155e-04, 2.20421916e-04,\n",
       "         1.52706562e-04, 2.02577329e-04, 2.14791159e-04, 1.82324572e-04,\n",
       "         2.75066275e-04, 5.84531421e-04, 3.11049595e-04, 3.32917958e-04]),\n",
       "  'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03,\n",
       "                     0.03, 0.03, 0.03, 0.04, 0.04, 0.04, 0.04, 0.05, 0.05,\n",
       "                     0.05, 0.05, 0.06, 0.06, 0.06, 0.06, 0.07, 0.07, 0.07,\n",
       "                     0.07, 0.08, 0.08, 0.08, 0.08, 0.09, 0.09, 0.09, 0.09,\n",
       "                     0.1, 0.1, 0.1, 0.1],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                     0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                     0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'learning_rate': 0.01, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.01, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.01, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.01, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.02, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.02, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.02, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.02, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.03, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.03, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.03, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.03, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.04, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.04, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.04, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.04, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.05, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.05, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.05, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.05, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.06, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.06, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.06, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.06, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.07, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.07, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.07, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.07, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.08, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.08, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.08, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.08, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.09, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.09, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.09, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.09, 'subsample': 0.9},\n",
       "   {'learning_rate': 0.1, 'subsample': 0.6},\n",
       "   {'learning_rate': 0.1, 'subsample': 0.7},\n",
       "   {'learning_rate': 0.1, 'subsample': 0.8},\n",
       "   {'learning_rate': 0.1, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.96395503, 0.96064815, 0.9619709 , 0.96296296, 0.96230159,\n",
       "         0.96395503, 0.96759259, 0.9646164 , 0.96428571, 0.96263228,\n",
       "         0.96825397, 0.96792328, 0.96428571, 0.96560847, 0.96660053,\n",
       "         0.96891534, 0.96230159, 0.96296296, 0.96626984, 0.9702381 ,\n",
       "         0.96362434, 0.95833333, 0.96560847, 0.96560847, 0.95899471,\n",
       "         0.95998677, 0.96660053, 0.96494709, 0.9537037 , 0.96296296,\n",
       "         0.96527778, 0.96395503, 0.96031746, 0.95767196, 0.96395503,\n",
       "         0.96593915, 0.95965608, 0.96097884, 0.96428571, 0.96031746]),\n",
       "  'split1_test_score': array([0.96759259, 0.96990741, 0.97089947, 0.97420635, 0.97089947,\n",
       "         0.97453704, 0.96891534, 0.96924603, 0.96891534, 0.97189153,\n",
       "         0.96560847, 0.9702381 , 0.96660053, 0.97321429, 0.96428571,\n",
       "         0.96792328, 0.96593915, 0.96891534, 0.96924603, 0.96759259,\n",
       "         0.9702381 , 0.96660053, 0.96957672, 0.96593915, 0.96825397,\n",
       "         0.97156085, 0.96957672, 0.96593915, 0.97056878, 0.96660053,\n",
       "         0.96759259, 0.96560847, 0.9702381 , 0.96759259, 0.96527778,\n",
       "         0.96164021, 0.97056878, 0.96527778, 0.96362434, 0.96395503]),\n",
       "  'split2_test_score': array([0.95205026, 0.95634921, 0.95469577, 0.95667989, 0.95502646,\n",
       "         0.95238095, 0.95701058, 0.95469577, 0.95568783, 0.95634921,\n",
       "         0.9619709 , 0.95535714, 0.95734127, 0.95734127, 0.96130952,\n",
       "         0.95072751, 0.95634921, 0.95998677, 0.95965608, 0.95535714,\n",
       "         0.95866402, 0.96329365, 0.96130952, 0.95866402, 0.95006614,\n",
       "         0.95866402, 0.96164021, 0.95833333, 0.9537037 , 0.95535714,\n",
       "         0.96329365, 0.95535714, 0.95998677, 0.96230159, 0.95634921,\n",
       "         0.95965608, 0.95767196, 0.96329365, 0.95535714, 0.95767196]),\n",
       "  'split3_test_score': array([0.95535714, 0.95601852, 0.95469577, 0.95601852, 0.95899471,\n",
       "         0.95469577, 0.95634921, 0.95833333, 0.95866402, 0.95800265,\n",
       "         0.95667989, 0.95767196, 0.95734127, 0.95998677, 0.95800265,\n",
       "         0.95667989, 0.96064815, 0.95469577, 0.95734127, 0.95634921,\n",
       "         0.95667989, 0.95436508, 0.95866402, 0.95502646, 0.95601852,\n",
       "         0.95899471, 0.95634921, 0.95271164, 0.95469577, 0.96064815,\n",
       "         0.95634921, 0.95337302, 0.95436508, 0.95767196, 0.95734127,\n",
       "         0.95205026, 0.95734127, 0.95568783, 0.95667989, 0.95568783]),\n",
       "  'split4_test_score': array([0.94781145, 0.94915825, 0.95117845, 0.94478114, 0.95420875,\n",
       "         0.95084175, 0.95185185, 0.95117845, 0.95521886, 0.95084175,\n",
       "         0.95252525, 0.95151515, 0.95286195, 0.95353535, 0.95387205,\n",
       "         0.94882155, 0.95656566, 0.95185185, 0.95151515, 0.95319865,\n",
       "         0.95387205, 0.94612795, 0.94882155, 0.95420875, 0.95488215,\n",
       "         0.94444444, 0.94949495, 0.95387205, 0.94949495, 0.94107744,\n",
       "         0.95117845, 0.95117845, 0.94478114, 0.94579125, 0.94882155,\n",
       "         0.95319865, 0.95016835, 0.94545455, 0.94781145, 0.95521886]),\n",
       "  'mean_test_score': array([0.95735329, 0.95841631, 0.95868807, 0.95892977, 0.9602862 ,\n",
       "         0.95928211, 0.96034392, 0.959614  , 0.96055435, 0.95994348,\n",
       "         0.9610077 , 0.96054113, 0.95968615, 0.96193723, 0.96081409,\n",
       "         0.95861352, 0.96036075, 0.95968254, 0.96080568, 0.96054714,\n",
       "         0.96061568, 0.95774411, 0.96079606, 0.95988937, 0.9576431 ,\n",
       "         0.95873016, 0.96073232, 0.95916065, 0.95643338, 0.95732924,\n",
       "         0.96073834, 0.95789442, 0.95793771, 0.95820587, 0.95834897,\n",
       "         0.95849687, 0.95908129, 0.95813853, 0.95755171, 0.95857023]),\n",
       "  'std_test_score': array([0.00736993, 0.00682291, 0.00704509, 0.00962664, 0.00604932,\n",
       "         0.00888199, 0.00671113, 0.0065542 , 0.00528305, 0.00706417,\n",
       "         0.00574952, 0.0072815 , 0.00503053, 0.00687268, 0.0045139 ,\n",
       "         0.00842152, 0.00361838, 0.00603798, 0.00633615, 0.00695862,\n",
       "         0.00576921, 0.00715449, 0.00704922, 0.00503442, 0.00603473,\n",
       "         0.00860653, 0.00719686, 0.00547128, 0.00729209, 0.00890754,\n",
       "         0.00607903, 0.00580039, 0.00833091, 0.00720525, 0.00591984,\n",
       "         0.00522   , 0.00658403, 0.00710635, 0.00604438, 0.00323715]),\n",
       "  'rank_test_score': array([38, 29, 25, 23, 14, 20, 13, 19,  9, 15,  2, 11, 17,  1,  3, 26, 12,\n",
       "         18,  4, 10,  8, 35,  5, 16, 36, 24,  7, 21, 40, 39,  6, 34, 33, 31,\n",
       "         30, 28, 22, 32, 37, 27], dtype=int32)},\n",
       " {'learning_rate': 0.04, 'subsample': 0.7},\n",
       " 0.9619372294372294)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the secone model is xgboosting\n",
    "import xgboost as xgb\n",
    "param_test1 = {\n",
    " 'learning_rate':[0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1],'subsample':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=7,reg_alpha= 0.1,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(x_train,y_train)\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.150769  , 0.15156908, 0.15098953, 0.15598807, 0.05827122,\n",
       "         0.20347676, 0.10227776, 0.20931802, 0.12343369, 0.09576588,\n",
       "         0.25820804, 0.10488214, 0.16686997, 0.18051348, 0.07797079,\n",
       "         0.27169366, 0.16647263, 0.2104466 , 0.21740918, 0.072925  ,\n",
       "         0.09516473, 0.11930132, 0.12788939, 0.10516205, 0.07706203,\n",
       "         0.13961973, 0.13789368, 0.19500728, 0.19925952, 0.07376137,\n",
       "         0.15063791, 0.25981636, 0.1709497 , 0.15280938, 0.07844424,\n",
       "         0.24699559, 0.21495113, 0.26780272, 0.25536313, 0.10249462,\n",
       "         0.14410324, 0.13486881, 0.2207942 , 0.17867975, 0.07668724,\n",
       "         0.25876169, 0.20421348, 0.23748856, 0.16646624, 0.1343751 ,\n",
       "         0.2428134 , 0.28647118, 0.35937028, 0.23006639, 0.10039134,\n",
       "         0.30037985, 0.37414069, 0.27983956, 0.29893332, 0.12095022,\n",
       "         0.17515793, 0.18947463, 0.14495497, 0.16065288, 0.08752165,\n",
       "         0.18151355, 0.27760863, 0.29179063, 0.28000097, 0.13293772,\n",
       "         0.24782548, 0.28430037, 0.22794948, 0.30349336, 0.08733835,\n",
       "         0.29362259, 0.32567868, 0.27632866, 0.28053994, 0.11446452]),\n",
       "  'std_fit_time': array([0.04488441, 0.06485046, 0.05371453, 0.04952698, 0.01344734,\n",
       "         0.11905936, 0.01638473, 0.06700943, 0.03772439, 0.03069775,\n",
       "         0.11687658, 0.01610734, 0.07457604, 0.0529987 , 0.04068779,\n",
       "         0.12505643, 0.06003999, 0.08383662, 0.05641717, 0.02803166,\n",
       "         0.06613036, 0.03949161, 0.03225269, 0.04142192, 0.0655674 ,\n",
       "         0.06878613, 0.06574316, 0.09487964, 0.07348279, 0.01758941,\n",
       "         0.02702128, 0.07780918, 0.04035102, 0.0338376 , 0.02407454,\n",
       "         0.15234126, 0.16327388, 0.0931012 , 0.08663009, 0.04754822,\n",
       "         0.06288428, 0.062233  , 0.1086604 , 0.08333838, 0.02541519,\n",
       "         0.07381502, 0.06445111, 0.11366583, 0.02384424, 0.03743221,\n",
       "         0.09020929, 0.07851097, 0.11042479, 0.05486283, 0.02384623,\n",
       "         0.07870304, 0.07419601, 0.09746592, 0.05797006, 0.05048619,\n",
       "         0.02669545, 0.11418773, 0.0479794 , 0.06554304, 0.03431773,\n",
       "         0.05567911, 0.07141841, 0.10862964, 0.07385947, 0.05390471,\n",
       "         0.08186336, 0.11638116, 0.07575065, 0.08114193, 0.04966473,\n",
       "         0.07138844, 0.10021318, 0.08191261, 0.05345983, 0.05853497]),\n",
       "  'mean_score_time': array([0.0029882 , 0.00266047, 0.00254631, 0.00237541, 0.00216746,\n",
       "         0.00224538, 0.00234275, 0.00241122, 0.00237761, 0.00212455,\n",
       "         0.00250764, 0.00236406, 0.00243468, 0.00256014, 0.00222096,\n",
       "         0.00264697, 0.00275412, 0.00246043, 0.0025207 , 0.00214849,\n",
       "         0.00224533, 0.00235343, 0.00245743, 0.00262413, 0.00216775,\n",
       "         0.00251379, 0.00231533, 0.00239959, 0.0024107 , 0.00231519,\n",
       "         0.00249753, 0.00247889, 0.00259271, 0.00236502, 0.00219378,\n",
       "         0.00291243, 0.00270276, 0.00283031, 0.00297489, 0.00246096,\n",
       "         0.00275297, 0.00257692, 0.00274086, 0.00273767, 0.00254703,\n",
       "         0.00294662, 0.00278301, 0.00299082, 0.00301709, 0.00267773,\n",
       "         0.00292668, 0.0029058 , 0.00306578, 0.00305872, 0.00247498,\n",
       "         0.00310359, 0.00302391, 0.00289364, 0.00310125, 0.00272365,\n",
       "         0.00273509, 0.00254426, 0.002601  , 0.00270977, 0.00242538,\n",
       "         0.00275593, 0.00279789, 0.00274539, 0.00260744, 0.00235882,\n",
       "         0.00295062, 0.00284452, 0.0031106 , 0.00286489, 0.00252132,\n",
       "         0.00311208, 0.00308671, 0.00307417, 0.00328279, 0.00247297]),\n",
       "  'std_score_time': array([1.18903796e-03, 2.36275261e-04, 1.46132347e-04, 1.34728430e-04,\n",
       "         1.85822223e-04, 1.40629569e-04, 1.54079906e-04, 1.03417900e-04,\n",
       "         1.70271171e-04, 1.53683440e-04, 2.31056777e-04, 1.44026972e-04,\n",
       "         1.69076761e-04, 1.67962259e-04, 2.92069458e-04, 2.26770157e-04,\n",
       "         2.42446473e-04, 1.86001787e-04, 2.05837440e-04, 3.97825101e-05,\n",
       "         1.84161684e-04, 2.74134798e-04, 3.11757447e-04, 5.29766782e-04,\n",
       "         1.47992878e-04, 1.17224924e-04, 1.04413772e-04, 1.81862254e-04,\n",
       "         1.86744030e-04, 2.78248787e-04, 2.21633870e-04, 1.77693570e-04,\n",
       "         1.19922280e-04, 1.18258942e-04, 5.82572468e-05, 5.77432544e-04,\n",
       "         1.72400301e-04, 2.34015646e-04, 2.50565863e-04, 2.13582544e-04,\n",
       "         1.45980049e-04, 1.68098632e-04, 3.34719545e-04, 2.99753985e-04,\n",
       "         2.50923520e-04, 3.02415411e-04, 9.89343915e-05, 1.67794016e-04,\n",
       "         2.46773692e-04, 3.47622249e-04, 2.80021037e-04, 1.84341903e-04,\n",
       "         1.17825622e-04, 4.50343386e-04, 2.30134990e-04, 1.79507728e-04,\n",
       "         8.01011775e-05, 1.42997048e-04, 2.96723913e-04, 3.56661170e-04,\n",
       "         2.59682487e-04, 2.43362662e-05, 2.81002795e-04, 3.55630689e-04,\n",
       "         8.49243364e-05, 2.86306960e-04, 1.54026477e-04, 2.74325955e-04,\n",
       "         8.67801183e-05, 1.02679284e-04, 4.56643223e-05, 1.64938476e-04,\n",
       "         2.52214648e-04, 2.62511627e-04, 3.99284998e-05, 4.35848491e-04,\n",
       "         4.51483201e-04, 6.57455943e-04, 6.15844614e-04, 6.27310129e-04]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                     0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7,\n",
       "                     0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                     0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                     0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                     0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9, 9, 9,\n",
       "                     9, 9, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 9,\n",
       "                     9, 9, 9, 9, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7, 7, 7,\n",
       "                     7, 9, 9, 9, 9, 9, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 7, 7,\n",
       "                     7, 7, 7, 9, 9, 9, 9, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_reg_alpha': masked_array(data=[1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100,\n",
       "                     1e-05, 0.01, 0.1, 1, 100, 1e-05, 0.01, 0.1, 1, 100],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'max_depth': 3, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 3, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 3, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 3, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 3, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 5, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 5, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 5, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 5, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 5, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 7, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 7, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 7, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 7, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 7, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 3, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 3, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 3, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 3, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 3, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 5, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 5, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 5, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 5, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 5, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 7, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 7, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 7, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 7, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 7, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 9, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 9, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 9, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 9, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.7, 'max_depth': 9, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 3, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 3, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 3, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 3, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 3, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 5, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 5, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 5, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 5, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 5, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 7, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 7, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 7, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 7, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 7, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 9, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 9, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 9, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 9, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.8, 'max_depth': 9, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 3, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 3, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 3, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 3, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 3, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 5, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 5, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 5, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 5, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 5, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 7, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 7, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 7, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 7, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 7, 'reg_alpha': 100},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 9, 'reg_alpha': 1e-05},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 9, 'reg_alpha': 0.01},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 9, 'reg_alpha': 0.1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 9, 'reg_alpha': 1},\n",
       "   {'colsample_bytree': 0.9, 'max_depth': 9, 'reg_alpha': 100}],\n",
       "  'split0_test_score': array([0.95403439, 0.95469577, 0.95469577, 0.95337302, 0.5       ,\n",
       "         0.96329365, 0.96362434, 0.9646164 , 0.96263228, 0.5       ,\n",
       "         0.96693122, 0.9672619 , 0.96527778, 0.96263228, 0.5       ,\n",
       "         0.96494709, 0.9619709 , 0.96660053, 0.96164021, 0.5       ,\n",
       "         0.95403439, 0.95403439, 0.9537037 , 0.95271164, 0.5       ,\n",
       "         0.96362434, 0.96263228, 0.9646164 , 0.96064815, 0.5       ,\n",
       "         0.96858466, 0.96858466, 0.9672619 , 0.96263228, 0.5       ,\n",
       "         0.96660053, 0.96825397, 0.96825397, 0.96263228, 0.5       ,\n",
       "         0.95138889, 0.95271164, 0.95271164, 0.94874339, 0.5       ,\n",
       "         0.96395503, 0.96527778, 0.96230159, 0.95998677, 0.5       ,\n",
       "         0.96560847, 0.96527778, 0.96164021, 0.96362434, 0.5       ,\n",
       "         0.96263228, 0.96064815, 0.96362434, 0.96395503, 0.5       ,\n",
       "         0.9510582 , 0.95238095, 0.95171958, 0.94808201, 0.5       ,\n",
       "         0.96660053, 0.96395503, 0.9646164 , 0.95899471, 0.5       ,\n",
       "         0.9672619 , 0.96660053, 0.96527778, 0.96164021, 0.5       ,\n",
       "         0.96263228, 0.9646164 , 0.96428571, 0.96329365, 0.5       ]),\n",
       "  'split1_test_score': array([0.96031746, 0.96031746, 0.95734127, 0.95337302, 0.5       ,\n",
       "         0.97486772, 0.97056878, 0.97123016, 0.96693122, 0.5       ,\n",
       "         0.97321429, 0.97354497, 0.9728836 , 0.97056878, 0.5       ,\n",
       "         0.97321429, 0.97420635, 0.97519841, 0.9728836 , 0.5       ,\n",
       "         0.95998677, 0.95601852, 0.95767196, 0.95502646, 0.5       ,\n",
       "         0.96693122, 0.9672619 , 0.96560847, 0.96494709, 0.5       ,\n",
       "         0.96990741, 0.96957672, 0.97156085, 0.97156085, 0.5       ,\n",
       "         0.97387566, 0.97387566, 0.97387566, 0.97222222, 0.5       ,\n",
       "         0.95899471, 0.95998677, 0.9593254 , 0.95601852, 0.5       ,\n",
       "         0.96891534, 0.96494709, 0.96626984, 0.96362434, 0.5       ,\n",
       "         0.97321429, 0.97156085, 0.97222222, 0.96693122, 0.5       ,\n",
       "         0.9702381 , 0.97222222, 0.96891534, 0.96957672, 0.5       ,\n",
       "         0.96031746, 0.95998677, 0.96097884, 0.95634921, 0.5       ,\n",
       "         0.96527778, 0.96395503, 0.96164021, 0.96362434, 0.5       ,\n",
       "         0.96891534, 0.96858466, 0.96693122, 0.96858466, 0.5       ,\n",
       "         0.96759259, 0.96527778, 0.96759259, 0.96825397, 0.5       ]),\n",
       "  'split2_test_score': array([0.94477513, 0.94642857, 0.94940476, 0.94609788, 0.5       ,\n",
       "         0.95568783, 0.95568783, 0.95568783, 0.95701058, 0.5       ,\n",
       "         0.95601852, 0.95436508, 0.95502646, 0.95899471, 0.5       ,\n",
       "         0.95171958, 0.95304233, 0.95502646, 0.96130952, 0.5       ,\n",
       "         0.94113757, 0.94146825, 0.94080688, 0.94543651, 0.5       ,\n",
       "         0.95800265, 0.95833333, 0.95833333, 0.95965608, 0.5       ,\n",
       "         0.95833333, 0.95502646, 0.95667989, 0.96263228, 0.5       ,\n",
       "         0.9593254 , 0.95965608, 0.96031746, 0.95998677, 0.5       ,\n",
       "         0.94279101, 0.94345238, 0.94775132, 0.95138889, 0.5       ,\n",
       "         0.9510582 , 0.95271164, 0.9537037 , 0.95601852, 0.5       ,\n",
       "         0.95734127, 0.95568783, 0.95403439, 0.95634921, 0.5       ,\n",
       "         0.95734127, 0.95601852, 0.95998677, 0.95899471, 0.5       ,\n",
       "         0.94675926, 0.94775132, 0.94742063, 0.94708995, 0.5       ,\n",
       "         0.95634921, 0.95502646, 0.95436508, 0.95701058, 0.5       ,\n",
       "         0.95667989, 0.95866402, 0.95866402, 0.95833333, 0.5       ,\n",
       "         0.95667989, 0.95502646, 0.95502646, 0.95899471, 0.5       ]),\n",
       "  'split3_test_score': array([0.94907407, 0.9484127 , 0.9457672 , 0.94444444, 0.5       ,\n",
       "         0.95800265, 0.95601852, 0.96097884, 0.95734127, 0.5       ,\n",
       "         0.96263228, 0.96164021, 0.96362434, 0.96296296, 0.5       ,\n",
       "         0.96560847, 0.96362434, 0.96693122, 0.96263228, 0.5       ,\n",
       "         0.95006614, 0.95072751, 0.95205026, 0.94642857, 0.5       ,\n",
       "         0.95634921, 0.95568783, 0.95701058, 0.95833333, 0.5       ,\n",
       "         0.95899471, 0.95866402, 0.95899471, 0.96296296, 0.5       ,\n",
       "         0.96097884, 0.95998677, 0.96130952, 0.9619709 , 0.5       ,\n",
       "         0.94973545, 0.94973545, 0.94742063, 0.94808201, 0.5       ,\n",
       "         0.95866402, 0.95734127, 0.95833333, 0.95734127, 0.5       ,\n",
       "         0.95998677, 0.95965608, 0.96064815, 0.96031746, 0.5       ,\n",
       "         0.96164021, 0.9619709 , 0.96263228, 0.96230159, 0.5       ,\n",
       "         0.9484127 , 0.94907407, 0.94708995, 0.94874339, 0.5       ,\n",
       "         0.95601852, 0.95535714, 0.95601852, 0.95800265, 0.5       ,\n",
       "         0.96097884, 0.96097884, 0.96164021, 0.96097884, 0.5       ,\n",
       "         0.96130952, 0.96097884, 0.96296296, 0.96164021, 0.5       ]),\n",
       "  'split4_test_score': array([0.94511785, 0.94444444, 0.94410774, 0.93670034, 0.5       ,\n",
       "         0.95050505, 0.94983165, 0.94949495, 0.95016835, 0.5       ,\n",
       "         0.95218855, 0.94848485, 0.95117845, 0.95050505, 0.5       ,\n",
       "         0.95319865, 0.95286195, 0.95185185, 0.94949495, 0.5       ,\n",
       "         0.94259259, 0.94276094, 0.94074074, 0.93771044, 0.5       ,\n",
       "         0.94983165, 0.94983165, 0.95185185, 0.94814815, 0.5       ,\n",
       "         0.95151515, 0.95319865, 0.95488215, 0.94680135, 0.5       ,\n",
       "         0.94949495, 0.95117845, 0.95151515, 0.95016835, 0.5       ,\n",
       "         0.94040404, 0.94074074, 0.93737374, 0.93164983, 0.5       ,\n",
       "         0.95084175, 0.94949495, 0.94949495, 0.94141414, 0.5       ,\n",
       "         0.95353535, 0.94915825, 0.95454545, 0.94579125, 0.5       ,\n",
       "         0.95319865, 0.95252525, 0.95151515, 0.94646465, 0.5       ,\n",
       "         0.93771044, 0.93737374, 0.93804714, 0.93232323, 0.5       ,\n",
       "         0.94713805, 0.95218855, 0.94511785, 0.94478114, 0.5       ,\n",
       "         0.94713805, 0.94949495, 0.94814815, 0.94208754, 0.5       ,\n",
       "         0.95151515, 0.95016835, 0.94747475, 0.93939394, 0.5       ]),\n",
       "  'mean_test_score': array([0.95066378, 0.95085979, 0.95026335, 0.94679774, 0.5       ,\n",
       "         0.96047138, 0.95914622, 0.96040164, 0.95881674, 0.5       ,\n",
       "         0.96219697, 0.9610594 , 0.96159812, 0.96113276, 0.5       ,\n",
       "         0.96173761, 0.96114117, 0.96312169, 0.96159211, 0.5       ,\n",
       "         0.94956349, 0.94900192, 0.94899471, 0.94746272, 0.5       ,\n",
       "         0.95894781, 0.9587494 , 0.95948413, 0.95834656, 0.5       ,\n",
       "         0.96146705, 0.9610101 , 0.9618759 , 0.96131794, 0.5       ,\n",
       "         0.96205507, 0.96259019, 0.96305435, 0.9613961 , 0.5       ,\n",
       "         0.94866282, 0.9493254 , 0.94891655, 0.94717653, 0.5       ,\n",
       "         0.95868687, 0.95795455, 0.95802068, 0.95567701, 0.5       ,\n",
       "         0.96193723, 0.96026816, 0.96061809, 0.95860269, 0.5       ,\n",
       "         0.9610101 , 0.96067701, 0.96133478, 0.96025854, 0.5       ,\n",
       "         0.94885161, 0.94931337, 0.94905123, 0.94651756, 0.5       ,\n",
       "         0.95827682, 0.95809644, 0.95635161, 0.95648268, 0.5       ,\n",
       "         0.96019481, 0.9608646 , 0.96013228, 0.95832492, 0.5       ,\n",
       "         0.95994589, 0.95921356, 0.95946849, 0.9583153 , 0.5       ]),\n",
       "  'std_test_score': array([0.00587393, 0.0058471 , 0.00507124, 0.00623625, 0.        ,\n",
       "         0.00828884, 0.00719768, 0.0074368 , 0.0056681 , 0.        ,\n",
       "         0.00751433, 0.00891775, 0.00770407, 0.00651393, 0.        ,\n",
       "         0.0081274 , 0.00789544, 0.00854405, 0.00741624, 0.        ,\n",
       "         0.00704948, 0.00588629, 0.00695664, 0.00608347, 0.        ,\n",
       "         0.00593894, 0.00594327, 0.00509003, 0.00556034, 0.        ,\n",
       "         0.00688292, 0.0068277 , 0.00643459, 0.00802259, 0.        ,\n",
       "         0.00808398, 0.00781095, 0.00758716, 0.00703011, 0.        ,\n",
       "         0.00660327, 0.00683357, 0.00720526, 0.00824958, 0.        ,\n",
       "         0.00710096, 0.00635538, 0.00596317, 0.00759012, 0.        ,\n",
       "         0.00687268, 0.0077124 , 0.00657151, 0.00730388, 0.        ,\n",
       "         0.00570374, 0.00668011, 0.00570321, 0.00770111, 0.        ,\n",
       "         0.00728054, 0.00732644, 0.00744289, 0.00782138, 0.        ,\n",
       "         0.00708781, 0.00490872, 0.00673099, 0.00627421, 0.        ,\n",
       "         0.00786689, 0.00673238, 0.00664456, 0.00879715, 0.        ,\n",
       "         0.00546429, 0.00580395, 0.0072801 , 0.00993072, 0.        ]),\n",
       "  'rank_test_score': array([50, 49, 51, 63, 65, 23, 33, 24, 35, 65,  4, 17,  9, 16, 65,  8, 15,\n",
       "          1, 10, 65, 52, 56, 57, 61, 65, 34, 36, 30, 39, 65, 11, 18,  7, 14,\n",
       "         65,  5,  3,  2, 12, 65, 60, 53, 58, 62, 65, 37, 45, 44, 48, 65,  6,\n",
       "         25, 22, 38, 65, 18, 21, 13, 26, 65, 59, 54, 55, 64, 65, 42, 43, 47,\n",
       "         46, 65, 27, 20, 28, 40, 65, 29, 32, 31, 41, 65], dtype=int32)},\n",
       " {'colsample_bytree': 0.6, 'max_depth': 9, 'reg_alpha': 0.1},\n",
       " 0.9631216931216932)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)],'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],'max_depth':list(range(3,10,2))\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.04, n_estimators=140, max_depth=7,reg_alpha= 0.1,\n",
    " min_child_weight=1, gamma=0, subsample=0.7, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.25453157, 0.30398035, 0.11866107, 0.1959353 , 0.17131119,\n",
       "         0.18117757, 0.25529542, 0.23777308, 0.26270638, 0.30693336,\n",
       "         0.22443333, 0.20856581, 0.27965012, 0.22988119, 0.14890008]),\n",
       "  'std_fit_time': array([0.06010042, 0.08548189, 0.04403994, 0.06352136, 0.05350969,\n",
       "         0.04331446, 0.04792554, 0.0496157 , 0.06049524, 0.09922321,\n",
       "         0.11202656, 0.06482128, 0.08823344, 0.08215914, 0.06434977]),\n",
       "  'mean_score_time': array([0.00274563, 0.00256743, 0.00248156, 0.00277047, 0.00254622,\n",
       "         0.00251565, 0.00256104, 0.00267601, 0.00267682, 0.00283561,\n",
       "         0.00258718, 0.00258932, 0.00304112, 0.00254164, 0.00236735]),\n",
       "  'std_score_time': array([1.97273243e-04, 1.15965640e-04, 1.03482848e-04, 2.00820092e-04,\n",
       "         2.34349314e-04, 8.65330831e-05, 1.50112882e-04, 2.81215538e-04,\n",
       "         2.26984835e-04, 3.81476480e-04, 1.33106221e-04, 2.27404066e-04,\n",
       "         4.88776221e-04, 2.29948044e-04, 3.09306170e-04]),\n",
       "  'param_gamma': masked_array(data=[0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.3, 0.3,\n",
       "                     0.3, 0.4, 0.4, 0.4],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': 0.0, 'min_child_weight': 1},\n",
       "   {'gamma': 0.0, 'min_child_weight': 3},\n",
       "   {'gamma': 0.0, 'min_child_weight': 5},\n",
       "   {'gamma': 0.1, 'min_child_weight': 1},\n",
       "   {'gamma': 0.1, 'min_child_weight': 3},\n",
       "   {'gamma': 0.1, 'min_child_weight': 5},\n",
       "   {'gamma': 0.2, 'min_child_weight': 1},\n",
       "   {'gamma': 0.2, 'min_child_weight': 3},\n",
       "   {'gamma': 0.2, 'min_child_weight': 5},\n",
       "   {'gamma': 0.3, 'min_child_weight': 1},\n",
       "   {'gamma': 0.3, 'min_child_weight': 3},\n",
       "   {'gamma': 0.3, 'min_child_weight': 5},\n",
       "   {'gamma': 0.4, 'min_child_weight': 1},\n",
       "   {'gamma': 0.4, 'min_child_weight': 3},\n",
       "   {'gamma': 0.4, 'min_child_weight': 5}],\n",
       "  'split0_test_score': array([0.96660053, 0.96230159, 0.9401455 , 0.96626984, 0.96296296,\n",
       "         0.94179894, 0.96660053, 0.96362434, 0.94146825, 0.96362434,\n",
       "         0.96263228, 0.94246032, 0.96164021, 0.9619709 , 0.93981481]),\n",
       "  'split1_test_score': array([0.97519841, 0.96362434, 0.91319444, 0.9755291 , 0.96296296,\n",
       "         0.91154101, 0.97652116, 0.96494709, 0.91137566, 0.97751323,\n",
       "         0.9672619 , 0.91402116, 0.97519841, 0.96593915, 0.91335979]),\n",
       "  'split2_test_score': array([0.95502646, 0.94477513, 0.93716931, 0.95238095, 0.94510582,\n",
       "         0.93683862, 0.95403439, 0.94543651, 0.93650794, 0.95337302,\n",
       "         0.94675926, 0.93683862, 0.95072751, 0.94510582, 0.93849206]),\n",
       "  'split3_test_score': array([0.96693122, 0.95965608, 0.94179894, 0.96395503, 0.95734127,\n",
       "         0.94179894, 0.96031746, 0.95701058, 0.94179894, 0.96296296,\n",
       "         0.96031746, 0.94146825, 0.96097884, 0.95866402, 0.94113757]),\n",
       "  'split4_test_score': array([0.95185185, 0.93030303, 0.90723906, 0.95387205, 0.92861953,\n",
       "         0.9043771 , 0.95252525, 0.93030303, 0.903367  , 0.95454545,\n",
       "         0.92693603, 0.9040404 , 0.95286195, 0.92659933, 0.90538721]),\n",
       "  'mean_test_score': array([0.96312169, 0.95213203, 0.92790945, 0.96240139, 0.95139851,\n",
       "         0.92727092, 0.96199976, 0.95226431, 0.92690356, 0.9624038 ,\n",
       "         0.95278139, 0.92776575, 0.96028139, 0.95165584, 0.92763829]),\n",
       "  'std_test_score': array([0.00854405, 0.01282758, 0.01464364, 0.00851909, 0.01312455,\n",
       "         0.01603262, 0.00881001, 0.01297187, 0.01625627, 0.00864183,\n",
       "         0.01461346, 0.01573411, 0.00861597, 0.01435451, 0.01514786]),\n",
       "  'rank_test_score': array([ 1,  8, 11,  3, 10, 14,  4,  7, 15,  2,  6, 12,  5,  9, 13],\n",
       "        dtype=int32)},\n",
       " {'gamma': 0.0, 'min_child_weight': 1},\n",
       " 0.9631216931216932)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    "  'min_child_weight':list(range(1,6,2)),'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.04, n_estimators=140, max_depth=9,reg_alpha= 0.1,\n",
    " min_child_weight=1, gamma=0, subsample=0.7, colsample_bytree=0.6,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(x_train,y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def modelfit(alg, x_trian,y_train,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(x_train, y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'],\n",
    "                          nfold=cv_folds,metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(x_train, y_train, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    movies_predictions = alg.predict(x_train)\n",
    "    movies_predprob = alg.predict_proba(x_train)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_train, movies_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, movies_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9836\n",
      "AUC Score (Train): 0.998553\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb1 = xgb.XGBClassifier(learning_rate =0.04, n_estimators=140, max_depth=9,reg_alpha= 0.1,min_child_weight=1, gamma=0, subsample=0.7, colsample_bytree=0.6,objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27)\n",
    "modelfit(xgb1, x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.91      0.89        70\n",
      "         1.0       0.91      0.85      0.88        68\n",
      "\n",
      "    accuracy                           0.88       138\n",
      "   macro avg       0.89      0.88      0.88       138\n",
      "weighted avg       0.89      0.88      0.88       138\n",
      "\n",
      "[[64  6]\n",
      " [10 58]]\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb1.predict(x_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.01040549, 0.0096839 , 0.01042132, 0.01401129, 0.01651096,\n",
       "         0.0179739 , 0.01944547, 0.02139821, 0.02410226, 0.02687306,\n",
       "         0.02857566, 0.034097  , 0.03344855, 0.03942523, 0.0382123 ,\n",
       "         0.00565424, 0.00811067, 0.01052699, 0.01327519, 0.01491742,\n",
       "         0.01695485, 0.01938934, 0.02465906, 0.02459641, 0.02701001,\n",
       "         0.02922683, 0.03143373, 0.03395376, 0.03536391, 0.03876824,\n",
       "         0.00584297, 0.00864844, 0.01061277, 0.01273856, 0.01472387,\n",
       "         0.01704793, 0.01890554, 0.02160101, 0.02346411, 0.0262846 ,\n",
       "         0.02821212, 0.03056884, 0.03332934, 0.03529987, 0.03844252,\n",
       "         0.00572824, 0.00785632, 0.01040573, 0.01301303, 0.0148807 ,\n",
       "         0.01671925, 0.01865983, 0.0209693 , 0.02413788, 0.02893395,\n",
       "         0.02822499, 0.03102612, 0.03303332, 0.03566084, 0.03733597,\n",
       "         0.00544524, 0.00767784, 0.0103034 , 0.01235933, 0.01434956,\n",
       "         0.01682377, 0.01950479, 0.02132454, 0.02417812, 0.0273458 ,\n",
       "         0.02921166, 0.03045516, 0.03244023, 0.03478966, 0.03693037]),\n",
       "  'std_fit_time': array([2.08546297e-03, 1.40223217e-03, 2.22033702e-04, 2.05260454e-03,\n",
       "         5.45000195e-04, 5.32811469e-04, 2.81666680e-04, 2.31004626e-04,\n",
       "         3.86901051e-04, 3.14377093e-04, 4.83208270e-04, 2.57392515e-03,\n",
       "         9.41412461e-04, 3.74052229e-03, 1.48287248e-03, 8.55780699e-05,\n",
       "         9.31992345e-05, 1.98050776e-04, 3.27085906e-04, 4.91012755e-04,\n",
       "         6.28903805e-04, 4.96330047e-04, 4.23852553e-03, 4.03665465e-04,\n",
       "         2.62428334e-04, 4.64246301e-04, 5.12434502e-04, 9.64664677e-04,\n",
       "         6.76196199e-04, 2.22704101e-03, 1.82475643e-04, 3.88763332e-04,\n",
       "         2.30858158e-04, 1.02997224e-04, 1.77936729e-04, 2.48123323e-04,\n",
       "         2.63802098e-04, 4.06252789e-04, 1.95671602e-04, 1.30642980e-03,\n",
       "         9.60822761e-04, 6.20337489e-04, 5.24573705e-04, 9.02548697e-04,\n",
       "         3.08770879e-04, 1.33099337e-04, 9.45709346e-05, 1.80734078e-04,\n",
       "         4.08891536e-04, 4.38925260e-04, 2.63554312e-04, 2.92076052e-04,\n",
       "         2.41463228e-04, 5.21020449e-04, 1.58073328e-03, 1.64473599e-04,\n",
       "         7.45375261e-04, 5.34177141e-04, 1.30812138e-04, 5.75532882e-04,\n",
       "         8.42810183e-05, 1.86366568e-04, 2.94257311e-04, 3.03321300e-04,\n",
       "         1.25590308e-04, 2.07800414e-04, 8.19003252e-04, 6.45267058e-04,\n",
       "         6.12284546e-04, 9.72388620e-04, 1.13198771e-03, 8.50501831e-04,\n",
       "         2.92036791e-04, 5.58567658e-04, 5.55935410e-04]),\n",
       "  'mean_score_time': array([0.00218582, 0.00174117, 0.00140128, 0.00146394, 0.00150461,\n",
       "         0.00139065, 0.00137234, 0.00136199, 0.00143728, 0.00145144,\n",
       "         0.00142274, 0.0015276 , 0.00139246, 0.00154104, 0.00139456,\n",
       "         0.00132604, 0.00141363, 0.00139246, 0.00140815, 0.00134091,\n",
       "         0.00134435, 0.00138645, 0.00147943, 0.00143161, 0.00143614,\n",
       "         0.0014698 , 0.00149226, 0.00144591, 0.00141454, 0.00140433,\n",
       "         0.0013226 , 0.00162201, 0.00139561, 0.00134764, 0.00132828,\n",
       "         0.00134797, 0.00135407, 0.00146618, 0.00148478, 0.00133901,\n",
       "         0.00154023, 0.00140638, 0.00146728, 0.00152631, 0.00140505,\n",
       "         0.00129547, 0.00131955, 0.00141215, 0.00138497, 0.00135608,\n",
       "         0.00133667, 0.00130773, 0.0013114 , 0.00147977, 0.00149961,\n",
       "         0.00144405, 0.00148525, 0.00146089, 0.00143228, 0.00142493,\n",
       "         0.00117002, 0.00120707, 0.00139985, 0.00130606, 0.00129476,\n",
       "         0.00135322, 0.00142179, 0.00133247, 0.00145168, 0.00141177,\n",
       "         0.00149655, 0.00142469, 0.00139017, 0.00138378, 0.00152607]),\n",
       "  'std_score_time': array([4.34777182e-04, 2.38242895e-04, 1.11761679e-04, 1.02058459e-04,\n",
       "         9.13292422e-05, 1.03072673e-04, 3.79794136e-05, 2.66204140e-05,\n",
       "         9.06721373e-05, 8.18438442e-05, 4.71216936e-05, 2.08838094e-04,\n",
       "         1.38730934e-05, 1.36679248e-04, 1.86323166e-05, 4.61250674e-05,\n",
       "         6.53067440e-05, 8.60869503e-05, 8.65857240e-05, 8.40253373e-05,\n",
       "         3.56352758e-05, 7.54538718e-05, 1.09004328e-04, 5.46168207e-05,\n",
       "         9.70853335e-05, 1.44422428e-04, 7.59450565e-05, 5.58031099e-05,\n",
       "         3.47434038e-05, 2.35087973e-05, 5.97573422e-05, 2.84800405e-04,\n",
       "         1.07846883e-04, 4.66951415e-05, 5.54111451e-05, 4.28531514e-05,\n",
       "         7.58865926e-05, 1.46956895e-04, 1.41658489e-04, 3.43684827e-05,\n",
       "         3.22433866e-04, 5.01446816e-05, 8.20662101e-05, 2.85398627e-04,\n",
       "         2.93734786e-05, 5.77045074e-05, 8.35237963e-05, 1.27917378e-04,\n",
       "         7.03296822e-05, 4.41720592e-05, 8.11165180e-05, 4.46119325e-05,\n",
       "         1.70215504e-05, 1.04664138e-04, 1.52769011e-04, 6.85781359e-05,\n",
       "         1.32392409e-04, 1.28337654e-04, 4.08676429e-05, 7.70986262e-05,\n",
       "         4.13128147e-05, 5.59570792e-05, 2.31561403e-04, 7.52259546e-05,\n",
       "         4.43003534e-05, 1.00796360e-04, 1.03398990e-04, 4.90079582e-05,\n",
       "         2.61219734e-05, 4.82978846e-05, 1.33174395e-04, 1.10130763e-04,\n",
       "         5.46509056e-05, 4.18927971e-05, 2.11948587e-04]),\n",
       "  'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                     0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                     0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5,\n",
       "                     0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                     0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                     0.7, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                     0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75,\n",
       "                     80, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70,\n",
       "                     75, 80, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65,\n",
       "                     70, 75, 80, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60,\n",
       "                     65, 70, 75, 80, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55,\n",
       "                     60, 65, 70, 75, 80],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'learning_rate': 0.1, 'n_estimators': 10},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 15},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 20},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 25},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 30},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 35},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 40},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 45},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 50},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 55},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 60},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 65},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 70},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 75},\n",
       "   {'learning_rate': 0.1, 'n_estimators': 80},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 10},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 15},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 20},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 25},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 30},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 35},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 40},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 45},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 50},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 55},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 60},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 65},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 70},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 75},\n",
       "   {'learning_rate': 0.3, 'n_estimators': 80},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 10},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 15},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 20},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 25},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 30},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 35},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 40},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 45},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 50},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 55},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 60},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 65},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 70},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 75},\n",
       "   {'learning_rate': 0.5, 'n_estimators': 80},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 10},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 15},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 20},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 25},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 30},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 35},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 40},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 45},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 50},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 55},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 60},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 65},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 70},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 75},\n",
       "   {'learning_rate': 0.7, 'n_estimators': 80},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 10},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 15},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 20},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 25},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 30},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 35},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 40},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 45},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 50},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 55},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 60},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 65},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 70},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 75},\n",
       "   {'learning_rate': 0.9, 'n_estimators': 80}],\n",
       "  'split0_test_score': array([0.85102513, 0.83878968, 0.83713624, 0.85780423, 0.88359788,\n",
       "         0.89384921, 0.89186508, 0.89864418, 0.91021825, 0.91071429,\n",
       "         0.91269841, 0.9265873 , 0.9292328 , 0.92460317, 0.92063492,\n",
       "         0.85912698, 0.8859127 , 0.86623677, 0.91402116, 0.91517857,\n",
       "         0.92873677, 0.92311508, 0.93237434, 0.94857804, 0.9525463 ,\n",
       "         0.94824735, 0.94791667, 0.95188492, 0.95386905, 0.93683862,\n",
       "         0.9036045 , 0.90542328, 0.90873016, 0.92774471, 0.94593254,\n",
       "         0.95634921, 0.94907407, 0.95568783, 0.9619709 , 0.95701058,\n",
       "         0.95800265, 0.95568783, 0.95271164, 0.95667989, 0.94808201,\n",
       "         0.92757937, 0.9212963 , 0.92741402, 0.93535053, 0.94262566,\n",
       "         0.95800265, 0.95535714, 0.94808201, 0.95271164, 0.95419974,\n",
       "         0.95684524, 0.94593254, 0.94146825, 0.94477513, 0.93617725,\n",
       "         0.91848545, 0.91484788, 0.92146164, 0.93088624, 0.9484127 ,\n",
       "         0.94080688, 0.95138889, 0.94047619, 0.94642857, 0.94212963,\n",
       "         0.94543651, 0.92757937, 0.92857143, 0.93320106, 0.93518519]),\n",
       "  'split1_test_score': array([0.81861772, 0.86094577, 0.85929233, 0.87318122, 0.87169312,\n",
       "         0.88144841, 0.88723545, 0.89384921, 0.89236111, 0.8953373 ,\n",
       "         0.89732143, 0.89467593, 0.89699074, 0.89335317, 0.89666005,\n",
       "         0.8422619 , 0.88673942, 0.88277116, 0.88260582, 0.89699074,\n",
       "         0.90724206, 0.90839947, 0.90707672, 0.9047619 , 0.90707672,\n",
       "         0.90410053, 0.90873016, 0.90873016, 0.90839947, 0.91369048,\n",
       "         0.8478836 , 0.87533069, 0.89748677, 0.89814815, 0.89368386,\n",
       "         0.89914021, 0.90277778, 0.90575397, 0.90410053, 0.89980159,\n",
       "         0.90443122, 0.91964286, 0.91484788, 0.91550926, 0.91534392,\n",
       "         0.84259259, 0.87037037, 0.90112434, 0.89914021, 0.9212963 ,\n",
       "         0.90013228, 0.91170635, 0.90575397, 0.91402116, 0.90641534,\n",
       "         0.91335979, 0.9130291 , 0.91534392, 0.91964286, 0.92526455,\n",
       "         0.84871032, 0.88062169, 0.90310847, 0.90145503, 0.92162698,\n",
       "         0.91964286, 0.92311508, 0.91121032, 0.91633598, 0.9103836 ,\n",
       "         0.91517857, 0.91352513, 0.91848545, 0.91881614, 0.91782407]),\n",
       "  'split2_test_score': array([0.79431217, 0.84474206, 0.83482143, 0.84275794, 0.84077381,\n",
       "         0.84126984, 0.84556878, 0.84308862, 0.84044312, 0.84606481,\n",
       "         0.84887566, 0.85152116, 0.85945767, 0.8587963 , 0.85499339,\n",
       "         0.8125    , 0.85333995, 0.85499339, 0.87070106, 0.88012566,\n",
       "         0.88839286, 0.89467593, 0.89236111, 0.89203042, 0.89467593,\n",
       "         0.89699074, 0.89054233, 0.90376984, 0.90178571, 0.9021164 ,\n",
       "         0.84044312, 0.85400132, 0.85350529, 0.86111111, 0.89169974,\n",
       "         0.88409392, 0.89252646, 0.8994709 , 0.90310847, 0.90244709,\n",
       "         0.90939153, 0.91534392, 0.91765873, 0.91435185, 0.90806878,\n",
       "         0.81779101, 0.83316799, 0.85796958, 0.86210317, 0.8859127 ,\n",
       "         0.88955026, 0.88955026, 0.89451058, 0.89914021, 0.90674603,\n",
       "         0.90443122, 0.91005291, 0.91699735, 0.91501323, 0.91468254,\n",
       "         0.81845238, 0.83829365, 0.86871693, 0.87863757, 0.89748677,\n",
       "         0.90972222, 0.90178571, 0.9103836 , 0.90575397, 0.90873016,\n",
       "         0.90839947, 0.91600529, 0.92195767, 0.91865079, 0.91832011]),\n",
       "  'split3_test_score': array([0.82705026, 0.84771825, 0.85350529, 0.87549603, 0.8953373 ,\n",
       "         0.89765212, 0.90658069, 0.91865079, 0.91468254, 0.9156746 ,\n",
       "         0.91898148, 0.91931217, 0.92509921, 0.92509921, 0.92642196,\n",
       "         0.83928571, 0.89070767, 0.89897487, 0.91914683, 0.91583995,\n",
       "         0.9198082 , 0.92179233, 0.92542989, 0.92757937, 0.92460317,\n",
       "         0.92857143, 0.93055556, 0.93253968, 0.93386243, 0.93518519,\n",
       "         0.8640873 , 0.9103836 , 0.91501323, 0.91931217, 0.92096561,\n",
       "         0.91865079, 0.91699735, 0.92212302, 0.92427249, 0.92757937,\n",
       "         0.92493386, 0.92791005, 0.92625661, 0.92691799, 0.92460317,\n",
       "         0.88458995, 0.92741402, 0.93634259, 0.9307209 , 0.93121693,\n",
       "         0.92559524, 0.92774471, 0.93055556, 0.93617725, 0.92724868,\n",
       "         0.93287037, 0.92857143, 0.9292328 , 0.92857143, 0.92691799,\n",
       "         0.88988095, 0.89583333, 0.91881614, 0.91914683, 0.90922619,\n",
       "         0.92542989, 0.91765873, 0.91335979, 0.92559524, 0.9212963 ,\n",
       "         0.93088624, 0.93220899, 0.9375    , 0.93551587, 0.93915344]),\n",
       "  'split4_test_score': array([0.75707071, 0.8       , 0.82188552, 0.81498316, 0.83164983,\n",
       "         0.83569024, 0.84343434, 0.84579125, 0.84680135, 0.8523569 ,\n",
       "         0.8510101 , 0.85387205, 0.86060606, 0.86195286, 0.86077441,\n",
       "         0.76616162, 0.81010101, 0.84511785, 0.85454545, 0.86515152,\n",
       "         0.86447811, 0.86026936, 0.86565657, 0.86666667, 0.86363636,\n",
       "         0.87020202, 0.87239057, 0.86835017, 0.87205387, 0.87609428,\n",
       "         0.7969697 , 0.82171717, 0.86043771, 0.86919192, 0.87575758,\n",
       "         0.88434343, 0.86750842, 0.87121212, 0.87457912, 0.87491582,\n",
       "         0.87946128, 0.88114478, 0.87676768, 0.87609428, 0.88451178,\n",
       "         0.81700337, 0.85488215, 0.86043771, 0.85942761, 0.87154882,\n",
       "         0.88333333, 0.88400673, 0.88518519, 0.88484848, 0.88282828,\n",
       "         0.88585859, 0.87845118, 0.87474747, 0.88181818, 0.89225589,\n",
       "         0.86111111, 0.86683502, 0.88956229, 0.89444444, 0.87912458,\n",
       "         0.88585859, 0.88148148, 0.88383838, 0.88552189, 0.87239057,\n",
       "         0.87643098, 0.88148148, 0.87946128, 0.89158249, 0.88585859]),\n",
       "  'mean_test_score': array([0.8096152 , 0.83843915, 0.84132816, 0.85284452, 0.86461039,\n",
       "         0.86998196, 0.87493687, 0.88000481, 0.88090127, 0.88402958,\n",
       "         0.88577742, 0.88919372, 0.8942773 , 0.89276094, 0.89189695,\n",
       "         0.82386724, 0.86536015, 0.86961881, 0.88820406, 0.89465729,\n",
       "         0.9017316 , 0.90165043, 0.90457973, 0.90792328, 0.9085077 ,\n",
       "         0.90962241, 0.91002706, 0.91305495, 0.91399411, 0.91278499,\n",
       "         0.85059764, 0.87337121, 0.88703463, 0.89510161, 0.90560786,\n",
       "         0.90851551, 0.90577682, 0.91084957, 0.9136063 , 0.91235089,\n",
       "         0.91524411, 0.91994589, 0.91764851, 0.91791065, 0.91612193,\n",
       "         0.85791126, 0.88142617, 0.89665765, 0.89734848, 0.91052008,\n",
       "         0.91132275, 0.91367304, 0.91281746, 0.91737975, 0.91548761,\n",
       "         0.91867304, 0.91520743, 0.91555796, 0.91796417, 0.91905964,\n",
       "         0.86732804, 0.87928632, 0.90033309, 0.90491402, 0.91117544,\n",
       "         0.91629209, 0.91508598, 0.91185366, 0.91592713, 0.91098605,\n",
       "         0.91526635, 0.91416005, 0.91719517, 0.91955327, 0.91926828]),\n",
       "  'std_test_score': array([0.03192152, 0.02054297, 0.01348273, 0.02230019, 0.0245333 ,\n",
       "         0.02633276, 0.02566727, 0.03021913, 0.0314059 , 0.02927739,\n",
       "         0.03010322, 0.03163004, 0.03008454, 0.02885404, 0.02956694,\n",
       "         0.03249152, 0.0307247 , 0.01928938, 0.024878  , 0.01978399,\n",
       "         0.02303108, 0.02312148, 0.02399088, 0.0282979 , 0.02968254,\n",
       "         0.02681406, 0.02703658, 0.02825192, 0.0280146 , 0.02254415,\n",
       "         0.03457784, 0.03299825, 0.02527591, 0.02641087, 0.02485396,\n",
       "         0.02705323, 0.02701699, 0.02779974, 0.02890186, 0.0278688 ,\n",
       "         0.0258989 , 0.02394874, 0.02442379, 0.0258891 , 0.02077517,\n",
       "         0.04262194, 0.037041  , 0.03270918, 0.03237687, 0.02720124,\n",
       "         0.02744227, 0.02608234, 0.02326717, 0.02451095, 0.02392615,\n",
       "         0.02435787, 0.02238287, 0.02247647, 0.02073355, 0.01503906,\n",
       "         0.03435059, 0.02598325, 0.01955164, 0.01838019, 0.02329929,\n",
       "         0.01824863, 0.023217  , 0.0179385 , 0.02025808, 0.02267724,\n",
       "         0.02327904, 0.01776254, 0.01994943, 0.01565113, 0.01880404]),\n",
       "  'rank_test_score': array([75, 73, 72, 70, 68, 64, 62, 60, 59, 57, 56, 53, 50, 51, 52, 74, 67,\n",
       "         65, 54, 49, 43, 44, 42, 38, 37, 35, 34, 24, 21, 26, 71, 63, 55, 48,\n",
       "         40, 36, 39, 32, 23, 27, 17,  1,  8,  7, 12, 69, 58, 47, 46, 33, 29,\n",
       "         22, 25,  9, 15,  5, 18, 14,  6,  4, 66, 61, 45, 41, 30, 11, 19, 28,\n",
       "         13, 31, 16, 20, 10,  2,  3], dtype=int32)},\n",
       " {'learning_rate': 0.5, 'n_estimators': 65},\n",
       " 0.9199458874458875)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the third model will be GBDT,tunning the hyperparameters.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_test1 = {'learning_rate':[0.1,0.3,0.5,0.7,0.9],'n_estimators':range(10,81,5)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=300,n_estimators = 50,max_features= 9\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features=9, subsample=0.8,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',iid=False,cv=5)\n",
    "gsearch1.fit(x_train,y_train)\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.03857379, 0.03192272, 0.02606397, 0.024435  , 0.02385912,\n",
       "         0.03085642, 0.0278017 , 0.02409902, 0.02416492, 0.02436323,\n",
       "         0.03001671, 0.02772846, 0.02389188, 0.02389054, 0.02398262,\n",
       "         0.02919483, 0.02738166, 0.02408729, 0.02422738, 0.02395053,\n",
       "         0.03177638, 0.0278945 , 0.02400942, 0.02412057, 0.02401896,\n",
       "         0.0346189 , 0.02966619, 0.02431035, 0.02508621, 0.02551365,\n",
       "         0.03196282, 0.02946835, 0.02548742, 0.02530966, 0.0253562 ,\n",
       "         0.03075342, 0.03376055, 0.02594438, 0.02719007, 0.0288424 ,\n",
       "         0.03677979, 0.03165884, 0.02693696, 0.02477341, 0.02497306,\n",
       "         0.03236914, 0.02969794, 0.02633891, 0.02549424, 0.02503648,\n",
       "         0.03062916, 0.02886605, 0.02432432, 0.02559681, 0.02569427,\n",
       "         0.03179088, 0.03029284, 0.02537985, 0.02700901, 0.02524123,\n",
       "         0.03494239, 0.02974315, 0.02511153, 0.02781177, 0.02563081,\n",
       "         0.03294821, 0.03011003, 0.02482195, 0.02540784, 0.02567873,\n",
       "         0.03107915, 0.02852077, 0.02569399, 0.02514281, 0.02521915,\n",
       "         0.03120446, 0.02990112, 0.02913213, 0.02618613, 0.02596302,\n",
       "         0.03386173, 0.03030443, 0.02455516, 0.02489471, 0.02703738,\n",
       "         0.03344455, 0.02935138, 0.025034  , 0.02555842, 0.02577505,\n",
       "         0.03221092, 0.03001733, 0.02440524, 0.02449365, 0.02436061,\n",
       "         0.03187017, 0.02979956, 0.02495522, 0.02507362, 0.02527728,\n",
       "         0.03366175, 0.02896624, 0.02569656, 0.02561049, 0.02493734,\n",
       "         0.03262401, 0.0286582 , 0.02504897, 0.02536025, 0.0253974 ,\n",
       "         0.0321352 , 0.02874684, 0.02516508, 0.02496343, 0.02454276,\n",
       "         0.03090558, 0.02933693, 0.02562966, 0.02515764, 0.02479029,\n",
       "         0.03383141, 0.02969799, 0.02477555, 0.02452946, 0.02447906,\n",
       "         0.03193917, 0.02892046, 0.02522497, 0.02543988, 0.02518568,\n",
       "         0.03203177, 0.0282186 , 0.02503657, 0.02484784, 0.02506657,\n",
       "         0.03034649, 0.02964902, 0.02535338, 0.02528787, 0.02527013,\n",
       "         0.03376403, 0.02971349, 0.02504077, 0.02553997, 0.02519174,\n",
       "         0.03220272, 0.02905059, 0.02483578, 0.02424097, 0.02522864,\n",
       "         0.03195462, 0.02958484, 0.02519526, 0.02498474, 0.02551765,\n",
       "         0.03074946, 0.02909999, 0.02437911, 0.02429242, 0.02528954,\n",
       "         0.03314853, 0.02838244, 0.02532372, 0.02410622, 0.02696581,\n",
       "         0.03370299, 0.028684  , 0.02686486, 0.02516961, 0.02531724,\n",
       "         0.03359208, 0.02887664, 0.02541356, 0.02512865, 0.02450557,\n",
       "         0.03124614, 0.02902732, 0.02613339, 0.02587442, 0.02715654]),\n",
       "  'std_fit_time': array([7.09144505e-03, 3.28659575e-03, 3.11324691e-04, 3.66840201e-04,\n",
       "         2.34157226e-04, 2.85498753e-04, 3.53748111e-04, 2.65544299e-04,\n",
       "         5.71176480e-05, 9.54967164e-04, 5.19832277e-04, 9.15763993e-05,\n",
       "         1.30815162e-04, 1.20095715e-04, 1.24127829e-04, 2.59120042e-04,\n",
       "         3.25883471e-04, 1.04428492e-04, 3.22929389e-04, 3.01672957e-04,\n",
       "         6.16603426e-04, 3.35732405e-04, 2.51669367e-04, 3.11389926e-04,\n",
       "         5.04439163e-04, 2.42964338e-03, 3.67364550e-04, 1.08135587e-04,\n",
       "         2.70690900e-04, 2.87454074e-04, 5.95068939e-04, 6.84457900e-04,\n",
       "         4.32495351e-04, 1.48101476e-04, 3.72640280e-04, 2.12972547e-04,\n",
       "         6.52737175e-03, 4.30337982e-04, 1.20940099e-03, 6.81978405e-04,\n",
       "         1.78323090e-03, 1.15070429e-03, 1.85687880e-03, 2.06644269e-04,\n",
       "         1.07321903e-04, 4.43940260e-04, 1.06142430e-04, 1.20541099e-03,\n",
       "         3.53203863e-04, 5.26271988e-04, 2.22721801e-04, 4.92708893e-04,\n",
       "         2.81508868e-04, 1.05701554e-03, 7.92813522e-04, 1.77233239e-03,\n",
       "         1.06766340e-03, 1.90457345e-04, 2.19378545e-03, 5.94874233e-04,\n",
       "         2.43969486e-03, 4.80101200e-04, 4.49899348e-04, 2.51910130e-03,\n",
       "         1.32599482e-03, 4.23347979e-04, 9.50121169e-04, 3.37456730e-04,\n",
       "         3.69666770e-04, 1.46949036e-03, 6.20010448e-04, 4.71834679e-04,\n",
       "         8.22442361e-04, 1.38612847e-04, 2.35728605e-04, 3.76276610e-04,\n",
       "         6.62407836e-04, 4.90531276e-03, 1.06241361e-03, 3.99786894e-04,\n",
       "         4.39246297e-04, 1.35891172e-03, 3.86437271e-04, 5.10424834e-04,\n",
       "         2.33673524e-03, 2.07662939e-03, 4.89291170e-04, 1.93976301e-04,\n",
       "         5.48089237e-04, 1.92197828e-04, 5.22176545e-04, 1.10569717e-03,\n",
       "         2.35897564e-04, 2.76936964e-04, 1.69378264e-04, 2.03862570e-03,\n",
       "         7.49853905e-04, 8.21506819e-04, 3.32165141e-04, 2.83394421e-04,\n",
       "         3.36967483e-04, 3.45342786e-04, 3.89795796e-04, 9.82404783e-04,\n",
       "         7.38470233e-04, 7.63531321e-04, 5.88659390e-04, 3.97584323e-04,\n",
       "         2.47447365e-04, 3.18508861e-04, 9.24271145e-04, 5.73943575e-04,\n",
       "         8.72143909e-04, 5.86060713e-04, 5.93600603e-04, 3.59827165e-04,\n",
       "         5.97082458e-04, 3.07698019e-04, 9.45073204e-05, 2.99021537e-04,\n",
       "         1.76642097e-04, 8.77957369e-04, 4.77018737e-04, 4.82843856e-04,\n",
       "         2.51811766e-04, 8.66185501e-04, 3.98450688e-04, 2.13779952e-04,\n",
       "         2.38277136e-04, 2.72423566e-04, 9.85613882e-04, 1.18953105e-04,\n",
       "         5.82139922e-04, 5.63377131e-04, 8.96206520e-04, 6.86090937e-04,\n",
       "         1.09224964e-03, 3.60896004e-04, 4.05451863e-04, 1.72436843e-04,\n",
       "         8.13417256e-04, 6.03270255e-04, 3.37771484e-04, 6.13414848e-04,\n",
       "         6.49771185e-04, 9.25576754e-04, 8.81010236e-04, 4.07179048e-04,\n",
       "         2.25322536e-04, 3.03892126e-04, 4.82403373e-04, 6.45630018e-04,\n",
       "         2.17196504e-04, 2.71502829e-04, 3.60238636e-04, 3.44747086e-04,\n",
       "         6.45240097e-04, 1.12781675e-04, 4.61389995e-04, 1.15242944e-03,\n",
       "         8.43549287e-04, 7.60570463e-04, 4.77386578e-04, 5.19724206e-04,\n",
       "         1.85544381e-03, 1.30140922e-03, 5.55914412e-04, 1.50124364e-03,\n",
       "         5.93963091e-04, 7.80692868e-04, 7.79412989e-04, 7.05870399e-04,\n",
       "         5.50788188e-04, 5.88185823e-04, 4.57712369e-04, 7.29623359e-04,\n",
       "         2.72161783e-04, 4.23971698e-04, 4.21619442e-04, 1.17879854e-03]),\n",
       "  'mean_score_time': array([0.00164299, 0.00141053, 0.00130572, 0.00132318, 0.00126424,\n",
       "         0.00143189, 0.00142932, 0.0012536 , 0.00128884, 0.0012394 ,\n",
       "         0.00142522, 0.00132184, 0.00127854, 0.00127811, 0.00129561,\n",
       "         0.00139456, 0.00130458, 0.00130434, 0.00125184, 0.00124445,\n",
       "         0.00138211, 0.00130482, 0.00121794, 0.00125642, 0.00125422,\n",
       "         0.00142393, 0.00143661, 0.00127983, 0.00130558, 0.00128622,\n",
       "         0.00146661, 0.001509  , 0.00132818, 0.00131516, 0.00134544,\n",
       "         0.00142894, 0.00158401, 0.00144901, 0.00130343, 0.00163479,\n",
       "         0.00145736, 0.00144634, 0.0014236 , 0.00139456, 0.00131459,\n",
       "         0.00149069, 0.00142121, 0.00134778, 0.00141659, 0.00135732,\n",
       "         0.00141659, 0.001408  , 0.00132008, 0.00129914, 0.00141439,\n",
       "         0.00146818, 0.0014523 , 0.00135465, 0.00131469, 0.00134335,\n",
       "         0.00177379, 0.00141482, 0.001337  , 0.00169945, 0.00135736,\n",
       "         0.00147667, 0.00141969, 0.0013196 , 0.00137272, 0.00132065,\n",
       "         0.00141068, 0.00144863, 0.00140276, 0.00140233, 0.00130744,\n",
       "         0.00153718, 0.0014679 , 0.00162268, 0.00132208, 0.00137157,\n",
       "         0.00152278, 0.00142279, 0.001267  , 0.00131874, 0.00135779,\n",
       "         0.00143456, 0.00149341, 0.00134726, 0.00132151, 0.00139499,\n",
       "         0.00143638, 0.0013936 , 0.00134015, 0.00131617, 0.00132065,\n",
       "         0.00148201, 0.00147891, 0.00136361, 0.00141325, 0.0013061 ,\n",
       "         0.00152473, 0.00143809, 0.00137596, 0.00131855, 0.00129943,\n",
       "         0.00145183, 0.00139184, 0.00133824, 0.00137868, 0.00132065,\n",
       "         0.00148163, 0.00139794, 0.00146556, 0.00134711, 0.00130043,\n",
       "         0.00158048, 0.00142894, 0.00139098, 0.00131555, 0.00134301,\n",
       "         0.00145292, 0.00139713, 0.00136228, 0.00128136, 0.00134921,\n",
       "         0.00145941, 0.00144958, 0.00133791, 0.00132947, 0.00141253,\n",
       "         0.00154848, 0.0013835 , 0.00137734, 0.00132623, 0.00130496,\n",
       "         0.00139122, 0.00143595, 0.00138545, 0.00135365, 0.00143518,\n",
       "         0.00149727, 0.00144982, 0.00134602, 0.00138707, 0.00131421,\n",
       "         0.00144787, 0.00150223, 0.00129342, 0.00129523, 0.00143709,\n",
       "         0.00147576, 0.00141435, 0.00134239, 0.00142145, 0.00135202,\n",
       "         0.00152378, 0.00137444, 0.00129199, 0.0012701 , 0.00130482,\n",
       "         0.00148411, 0.00133801, 0.00132017, 0.00143528, 0.00147042,\n",
       "         0.00147142, 0.00145144, 0.00138321, 0.00132117, 0.00134826,\n",
       "         0.00153322, 0.00143723, 0.00134678, 0.00130272, 0.00129962,\n",
       "         0.00142722, 0.00144687, 0.00143394, 0.0013711 , 0.00143266]),\n",
       "  'std_score_time': array([1.79775539e-04, 5.12269157e-05, 4.86779511e-05, 7.18046783e-05,\n",
       "         8.24573474e-05, 1.10045442e-04, 1.23232288e-04, 3.62543653e-05,\n",
       "         6.89087275e-05, 4.29033157e-05, 1.01121794e-04, 4.01717689e-05,\n",
       "         4.39895136e-05, 8.28491904e-05, 5.81096855e-05, 1.51146097e-05,\n",
       "         5.41888035e-05, 1.16162504e-04, 5.13331534e-05, 4.02936145e-05,\n",
       "         1.81930717e-05, 3.71741588e-05, 3.34485547e-05, 4.31779667e-05,\n",
       "         5.88619887e-05, 2.50158244e-05, 5.40455742e-05, 5.47025959e-05,\n",
       "         2.66005052e-05, 2.10184064e-05, 6.36970563e-05, 1.18474738e-04,\n",
       "         1.03896613e-04, 3.71646771e-05, 7.05047559e-05, 2.91158190e-05,\n",
       "         3.78649431e-04, 2.06788591e-04, 2.86784947e-05, 2.91996458e-04,\n",
       "         5.65908684e-05, 1.02777446e-04, 1.42189211e-04, 1.18609579e-04,\n",
       "         1.75301060e-05, 9.78705915e-05, 8.92841131e-05, 9.69653960e-05,\n",
       "         1.52361866e-04, 5.15626136e-05, 4.16070410e-05, 4.48963392e-05,\n",
       "         5.49125970e-05, 5.43470954e-05, 1.33796003e-04, 6.59034841e-05,\n",
       "         1.00446582e-04, 1.16668460e-04, 3.75172373e-05, 4.96404659e-05,\n",
       "         3.86605512e-04, 8.35685383e-05, 6.75057946e-05, 5.01088384e-04,\n",
       "         1.27978634e-04, 9.34748735e-05, 8.67476753e-06, 4.31892871e-05,\n",
       "         9.80859482e-05, 3.11091573e-05, 2.60068228e-05, 1.52931051e-04,\n",
       "         1.26179131e-04, 1.91701016e-04, 5.83658031e-05, 1.18609790e-04,\n",
       "         6.66788868e-05, 4.60421698e-04, 6.98370955e-05, 1.19302751e-04,\n",
       "         9.91698633e-05, 1.84336883e-05, 3.03425089e-05, 3.32025243e-05,\n",
       "         6.46350965e-05, 5.46123244e-05, 1.60014316e-04, 7.39951410e-05,\n",
       "         4.94347916e-05, 7.48471832e-05, 6.24209892e-05, 2.37211030e-05,\n",
       "         5.98038207e-05, 5.70207528e-05, 1.02461576e-04, 5.28848740e-05,\n",
       "         9.05378034e-05, 9.61524838e-05, 1.35033817e-04, 3.00052979e-05,\n",
       "         8.54865965e-05, 8.70744865e-05, 9.15011121e-05, 2.46495756e-05,\n",
       "         6.44533927e-05, 6.46984914e-05, 3.09641030e-05, 5.54127043e-05,\n",
       "         1.01804633e-04, 6.68639624e-05, 9.74381001e-05, 3.82501280e-05,\n",
       "         3.29694294e-04, 8.49155007e-05, 3.68199191e-05, 1.88696761e-04,\n",
       "         9.37608579e-05, 1.45987837e-04, 5.56093946e-05, 9.91113805e-05,\n",
       "         5.08584329e-05, 2.74316091e-05, 1.16064104e-04, 4.68992071e-05,\n",
       "         7.91473557e-05, 8.12726098e-05, 5.24163124e-05, 4.32106560e-05,\n",
       "         5.73921410e-05, 1.47794260e-04, 1.30794911e-04, 3.27293745e-05,\n",
       "         1.03582707e-04, 8.17577043e-05, 5.28658672e-05, 3.24646622e-05,\n",
       "         8.11452161e-05, 9.34451198e-05, 6.59263543e-05, 1.70526435e-04,\n",
       "         1.60838170e-04, 9.70536411e-05, 8.10772658e-05, 9.44873494e-05,\n",
       "         3.53755329e-05, 2.56121485e-05, 2.66115568e-04, 4.00333122e-05,\n",
       "         7.85273639e-05, 1.45515404e-04, 9.08922671e-05, 5.50971667e-05,\n",
       "         6.05129838e-05, 1.04291056e-04, 1.03615892e-04, 1.90359306e-04,\n",
       "         2.81844242e-05, 2.99007697e-05, 4.71980636e-05, 6.92218115e-05,\n",
       "         3.37219966e-05, 3.48750235e-05, 3.79759411e-05, 1.97827204e-04,\n",
       "         1.92830353e-04, 6.91179696e-05, 7.95963060e-05, 1.19691123e-04,\n",
       "         3.74748504e-05, 5.87325188e-05, 1.10143335e-04, 1.09720158e-04,\n",
       "         5.93411151e-05, 3.06428632e-05, 4.89280003e-05, 6.62318745e-05,\n",
       "         5.57819181e-05, 1.32439373e-04, 9.24457272e-05, 1.08989997e-04]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                     3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                     7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                     9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 13,\n",
       "                     13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                     13, 13, 13, 13, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                     15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17, 17, 17,\n",
       "                     17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                     17, 17, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "                     19, 19, 19, 19, 19, 19, 19, 19],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_leaf': masked_array(data=[50, 50, 50, 50, 50, 60, 60, 60, 60, 60, 70, 70, 70, 70,\n",
       "                     70, 80, 80, 80, 80, 80, 50, 50, 50, 50, 50, 60, 60, 60,\n",
       "                     60, 60, 70, 70, 70, 70, 70, 80, 80, 80, 80, 80, 50, 50,\n",
       "                     50, 50, 50, 60, 60, 60, 60, 60, 70, 70, 70, 70, 70, 80,\n",
       "                     80, 80, 80, 80, 50, 50, 50, 50, 50, 60, 60, 60, 60, 60,\n",
       "                     70, 70, 70, 70, 70, 80, 80, 80, 80, 80, 50, 50, 50, 50,\n",
       "                     50, 60, 60, 60, 60, 60, 70, 70, 70, 70, 70, 80, 80, 80,\n",
       "                     80, 80, 50, 50, 50, 50, 50, 60, 60, 60, 60, 60, 70, 70,\n",
       "                     70, 70, 70, 80, 80, 80, 80, 80, 50, 50, 50, 50, 50, 60,\n",
       "                     60, 60, 60, 60, 70, 70, 70, 70, 70, 80, 80, 80, 80, 80,\n",
       "                     50, 50, 50, 50, 50, 60, 60, 60, 60, 60, 70, 70, 70, 70,\n",
       "                     70, 80, 80, 80, 80, 80, 50, 50, 50, 50, 50, 60, 60, 60,\n",
       "                     60, 60, 70, 70, 70, 70, 70, 80, 80, 80, 80, 80],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_split': masked_array(data=[100, 300, 500, 700, 900, 100, 300, 500, 700, 900, 100,\n",
       "                     300, 500, 700, 900, 100, 300, 500, 700, 900, 100, 300,\n",
       "                     500, 700, 900, 100, 300, 500, 700, 900, 100, 300, 500,\n",
       "                     700, 900, 100, 300, 500, 700, 900, 100, 300, 500, 700,\n",
       "                     900, 100, 300, 500, 700, 900, 100, 300, 500, 700, 900,\n",
       "                     100, 300, 500, 700, 900, 100, 300, 500, 700, 900, 100,\n",
       "                     300, 500, 700, 900, 100, 300, 500, 700, 900, 100, 300,\n",
       "                     500, 700, 900, 100, 300, 500, 700, 900, 100, 300, 500,\n",
       "                     700, 900, 100, 300, 500, 700, 900, 100, 300, 500, 700,\n",
       "                     900, 100, 300, 500, 700, 900, 100, 300, 500, 700, 900,\n",
       "                     100, 300, 500, 700, 900, 100, 300, 500, 700, 900, 100,\n",
       "                     300, 500, 700, 900, 100, 300, 500, 700, 900, 100, 300,\n",
       "                     500, 700, 900, 100, 300, 500, 700, 900, 100, 300, 500,\n",
       "                     700, 900, 100, 300, 500, 700, 900, 100, 300, 500, 700,\n",
       "                     900, 100, 300, 500, 700, 900, 100, 300, 500, 700, 900,\n",
       "                     100, 300, 500, 700, 900, 100, 300, 500, 700, 900, 100,\n",
       "                     300, 500, 700, 900],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3,\n",
       "    'min_samples_leaf': 50,\n",
       "    'min_samples_split': 100},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 3, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 5, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 7, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 9, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 11, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 13, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 15, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 17, 'min_samples_leaf': 80, 'min_samples_split': 900},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 50, 'min_samples_split': 300},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 50, 'min_samples_split': 700},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 50, 'min_samples_split': 900},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 60, 'min_samples_split': 300},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 60, 'min_samples_split': 500},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 60, 'min_samples_split': 700},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 60, 'min_samples_split': 900},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 70, 'min_samples_split': 100},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 70, 'min_samples_split': 300},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 70, 'min_samples_split': 500},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 70, 'min_samples_split': 700},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 70, 'min_samples_split': 900},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 80, 'min_samples_split': 100},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 80, 'min_samples_split': 300},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 80, 'min_samples_split': 500},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 80, 'min_samples_split': 700},\n",
       "   {'max_depth': 19, 'min_samples_leaf': 80, 'min_samples_split': 900}],\n",
       "  'split0_test_score': array([0.92460317, 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91534392, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ,\n",
       "         0.9239418 , 0.88029101, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91898148, 0.87962963, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86871693, 0.82043651, 0.5       , 0.5       , 0.5       ,\n",
       "         0.81679894, 0.78257275, 0.5       , 0.5       , 0.5       ]),\n",
       "  'split1_test_score': array([0.90062831, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90724206, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90393519, 0.86193783, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91650132, 0.85565476, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85780423, 0.79513889, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83614418, 0.78835979, 0.5       , 0.5       , 0.5       ]),\n",
       "  'split2_test_score': array([0.87880291, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88624339, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89252646, 0.85945767, 0.5       , 0.5       , 0.5       ,\n",
       "         0.87450397, 0.85350529, 0.5       , 0.5       , 0.5       ,\n",
       "         0.85929233, 0.86458333, 0.5       , 0.5       , 0.5       ,\n",
       "         0.77662037, 0.70601852, 0.5       , 0.5       , 0.5       ]),\n",
       "  'split3_test_score': array([0.91468254, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91666667, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91402116, 0.88194444, 0.5       , 0.5       , 0.5       ,\n",
       "         0.92956349, 0.87731481, 0.5       , 0.5       , 0.5       ,\n",
       "         0.91865079, 0.86838624, 0.5       , 0.5       , 0.5       ,\n",
       "         0.80489418, 0.77695106, 0.5       , 0.5       , 0.5       ]),\n",
       "  'split4_test_score': array([0.89494949, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ,\n",
       "         0.88855219, 0.84292929, 0.5       , 0.5       , 0.5       ,\n",
       "         0.89225589, 0.85639731, 0.5       , 0.5       , 0.5       ,\n",
       "         0.82441077, 0.78989899, 0.5       , 0.5       , 0.5       ,\n",
       "         0.83670034, 0.79259259, 0.5       , 0.5       , 0.5       ]),\n",
       "  'mean_test_score': array([0.90273329, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90355038, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90459536, 0.86531205, 0.5       , 0.5       , 0.5       ,\n",
       "         0.90636123, 0.86450036, 0.5       , 0.5       , 0.5       ,\n",
       "         0.86577501, 0.82768879, 0.5       , 0.5       , 0.5       ,\n",
       "         0.8142316 , 0.76929894, 0.5       , 0.5       , 0.5       ]),\n",
       "  'std_test_score': array([0.01586668, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.01226255, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ,\n",
       "         0.01316517, 0.01447517, 0.        , 0.        , 0.        ,\n",
       "         0.02007129, 0.01147084, 0.        , 0.        , 0.        ,\n",
       "         0.03040086, 0.03333962, 0.        , 0.        , 0.        ,\n",
       "         0.02233109, 0.03207825, 0.        , 0.        , 0.        ]),\n",
       "  'rank_test_score': array([18, 28, 73, 73, 73, 17, 37, 73, 73, 73, 19, 46, 73, 73, 73, 55, 64,\n",
       "         73, 73, 73,  9, 28, 73, 73, 73,  1, 37, 73, 73, 73, 19, 46, 73, 73,\n",
       "         73, 55, 64, 73, 73, 73,  9, 28, 73, 73, 73,  1, 37, 73, 73, 73, 19,\n",
       "         46, 73, 73, 73, 55, 64, 73, 73, 73,  9, 28, 73, 73, 73,  1, 37, 73,\n",
       "         73, 73, 19, 46, 73, 73, 73, 55, 64, 73, 73, 73,  9, 28, 73, 73, 73,\n",
       "          1, 37, 73, 73, 73, 19, 46, 73, 73, 73, 55, 64, 73, 73, 73,  9, 28,\n",
       "         73, 73, 73,  1, 37, 73, 73, 73, 19, 46, 73, 73, 73, 55, 64, 73, 73,\n",
       "         73,  9, 28, 73, 73, 73,  1, 37, 73, 73, 73, 19, 46, 73, 73, 73, 55,\n",
       "         64, 73, 73, 73,  9, 28, 73, 73, 73,  1, 37, 73, 73, 73, 19, 46, 73,\n",
       "         73, 73, 55, 64, 73, 73, 73,  9, 28, 73, 73, 73,  1, 37, 73, 73, 73,\n",
       "         19, 46, 73, 73, 73, 55, 64, 73, 73, 73], dtype=int32)},\n",
       " {'max_depth': 5, 'min_samples_leaf': 60, 'min_samples_split': 100},\n",
       " 0.9063612313612314)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(3,20,2), 'min_samples_split':range(100,1001,200), 'min_samples_leaf':range(50,81,10)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.5, min_samples_split=300,n_estimators = 65,max_features= 9,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features=9, subsample=0.8,random_state=10), \n",
    "                       param_grid = param_test2, scoring='roc_auc',iid=False,cv=5)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.02993999, 0.03205519, 0.0324954 , 0.03843536, 0.03776169,\n",
       "         0.02444453, 0.02951221, 0.03249092, 0.0355649 , 0.03652182,\n",
       "         0.02350922, 0.02777905, 0.03053422, 0.03388534, 0.03767014,\n",
       "         0.02464924, 0.0294714 , 0.03195071, 0.03399105, 0.03860445,\n",
       "         0.02506022, 0.02943478, 0.03234677, 0.03580546, 0.03777051,\n",
       "         0.02339282, 0.02820759, 0.0307198 , 0.03445749, 0.04213743,\n",
       "         0.02553148, 0.03374329, 0.03371482, 0.03647699, 0.03833971,\n",
       "         0.0248518 , 0.02999797, 0.03255553, 0.03660188, 0.03993897,\n",
       "         0.02442417, 0.03105378, 0.03309302, 0.03777509, 0.03727722,\n",
       "         0.02865505, 0.03073616, 0.03181806, 0.03579192, 0.03900161,\n",
       "         0.02528815, 0.02965035, 0.03275924, 0.03578744, 0.039821  ,\n",
       "         0.02459426, 0.02921886, 0.03201485, 0.03587618, 0.04005299,\n",
       "         0.02441807, 0.02855792, 0.03247576, 0.03571262, 0.0400538 ,\n",
       "         0.02501197, 0.02850828, 0.03769207, 0.03987098, 0.04115062,\n",
       "         0.02581067, 0.029847  , 0.0340735 , 0.03741641, 0.04143562,\n",
       "         0.02524977, 0.03020782, 0.0341054 , 0.03757977, 0.04123206,\n",
       "         0.02534132, 0.03001442, 0.03345561, 0.03763618, 0.04099536,\n",
       "         0.02553525, 0.03039522, 0.03332725, 0.03747997, 0.04130898,\n",
       "         0.02544422, 0.02983022, 0.03342633, 0.03712602, 0.04114313,\n",
       "         0.02522759, 0.02999063, 0.03343134, 0.03686438, 0.04076715,\n",
       "         0.02495174, 0.02941937, 0.03268957, 0.03837566, 0.0422852 ,\n",
       "         0.02394381, 0.03004332, 0.03350506, 0.03948493, 0.04092708,\n",
       "         0.02603602, 0.03083811, 0.03241591, 0.03792815, 0.04216743,\n",
       "         0.02478466, 0.02966199, 0.03295794, 0.03729162, 0.04106746,\n",
       "         0.02462001, 0.02891154, 0.03335795, 0.03734832, 0.04401588,\n",
       "         0.0258091 , 0.03019137, 0.03421073, 0.03963861, 0.04400373,\n",
       "         0.02573795, 0.03048711, 0.03379498, 0.03832564, 0.04177008,\n",
       "         0.02674313, 0.02991781, 0.03366804, 0.03781042, 0.04291916,\n",
       "         0.02639804, 0.02947936, 0.03272061, 0.03818698, 0.04181757,\n",
       "         0.02448077, 0.02992625, 0.03545756, 0.03762341, 0.04051123]),\n",
       "  'std_fit_time': array([4.68209908e-03, 1.96449960e-03, 5.63473420e-04, 3.19534988e-03,\n",
       "         1.10545943e-03, 4.28170307e-04, 2.86122933e-04, 9.11431993e-04,\n",
       "         1.04499140e-03, 1.54619888e-04, 2.58437751e-04, 4.68207797e-04,\n",
       "         2.54904470e-04, 5.45068895e-04, 1.38810530e-03, 6.00009685e-04,\n",
       "         2.96910268e-04, 3.98131872e-04, 5.83684938e-04, 7.51699841e-04,\n",
       "         3.84205764e-04, 3.09412118e-04, 2.65492353e-04, 6.44549096e-05,\n",
       "         6.19211781e-04, 2.24235106e-04, 2.57163253e-04, 3.96905840e-04,\n",
       "         8.55539475e-04, 5.62219480e-03, 5.47222702e-04, 2.49417662e-03,\n",
       "         9.33484759e-04, 1.59323889e-04, 4.68795113e-04, 2.50525769e-04,\n",
       "         2.93735931e-04, 4.92911841e-04, 5.40832514e-04, 1.86193204e-03,\n",
       "         3.86062941e-04, 3.39869808e-03, 1.63338570e-03, 1.30670635e-03,\n",
       "         5.91368591e-04, 4.45405777e-03, 8.75082043e-04, 2.36746773e-04,\n",
       "         2.15231500e-04, 8.82350520e-04, 1.87097217e-04, 3.16368306e-04,\n",
       "         2.21654069e-04, 3.19238813e-04, 8.52148515e-04, 1.98233853e-04,\n",
       "         5.25336269e-04, 2.82591458e-04, 8.85832706e-04, 6.75777022e-04,\n",
       "         4.71660972e-04, 1.80285981e-04, 7.29940126e-04, 3.30700565e-04,\n",
       "         8.40949617e-04, 2.43063615e-04, 4.58763159e-04, 5.99312320e-03,\n",
       "         3.84774209e-03, 5.08776609e-04, 6.89203946e-04, 7.49619750e-04,\n",
       "         1.10602054e-03, 6.39460113e-04, 4.16634720e-04, 1.85279764e-04,\n",
       "         2.47729290e-04, 6.53641301e-04, 6.45489038e-04, 3.15703270e-04,\n",
       "         1.54098499e-04, 3.33872804e-04, 4.66854968e-04, 1.14122369e-03,\n",
       "         5.37341169e-04, 1.78134173e-04, 2.85438897e-04, 7.46297920e-04,\n",
       "         4.16781225e-04, 8.71385831e-04, 7.82180649e-04, 4.96345453e-04,\n",
       "         3.12870821e-04, 8.72149989e-04, 4.52116802e-04, 3.32770656e-04,\n",
       "         5.44742543e-04, 7.95126546e-04, 6.67180025e-04, 5.32658426e-04,\n",
       "         4.98398752e-04, 3.37875666e-04, 1.94855466e-04, 4.27532616e-04,\n",
       "         9.60172177e-04, 6.72372530e-04, 3.96104853e-04, 3.36166429e-04,\n",
       "         1.27482027e-03, 6.49684225e-04, 1.66894364e-03, 1.62361027e-03,\n",
       "         2.95338378e-04, 4.31307984e-04, 5.29896821e-04, 4.45599964e-04,\n",
       "         5.71606455e-04, 1.89404473e-04, 4.97402702e-04, 7.67440595e-04,\n",
       "         1.57296987e-03, 6.50554291e-04, 1.26096755e-03, 3.99957478e-04,\n",
       "         2.74159142e-03, 4.57736511e-04, 2.84822439e-04, 2.01938673e-04,\n",
       "         1.08804819e-03, 2.30552205e-03, 2.14006163e-04, 2.68265610e-04,\n",
       "         8.61569411e-04, 3.44225425e-04, 9.30607236e-04, 9.61568246e-04,\n",
       "         6.84291786e-04, 2.24724606e-04, 2.53954428e-04, 6.53924263e-04,\n",
       "         1.75966351e-03, 1.08949932e-03, 7.24910353e-04, 8.96869959e-04,\n",
       "         7.93676515e-04, 4.54480082e-04, 4.95195478e-04, 1.54165932e-03,\n",
       "         8.89265006e-04, 8.01586347e-04]),\n",
       "  'mean_score_time': array([0.00177746, 0.0015317 , 0.00151076, 0.00152264, 0.00150676,\n",
       "         0.00135236, 0.00140843, 0.00140114, 0.00160985, 0.00147438,\n",
       "         0.00125685, 0.00134215, 0.00137324, 0.00147533, 0.00145497,\n",
       "         0.00150471, 0.00141668, 0.0014564 , 0.00141482, 0.00146465,\n",
       "         0.00132113, 0.0015408 , 0.00145316, 0.00148463, 0.00157261,\n",
       "         0.0012548 , 0.00141063, 0.00137839, 0.00148239, 0.00159144,\n",
       "         0.0014502 , 0.00161672, 0.00148611, 0.00148425, 0.00151525,\n",
       "         0.00137291, 0.00161662, 0.00146542, 0.00163355, 0.00159283,\n",
       "         0.0013206 , 0.00151606, 0.00141864, 0.00167694, 0.00146537,\n",
       "         0.00154653, 0.00147548, 0.00152421, 0.00151997, 0.00159178,\n",
       "         0.0013689 , 0.00136304, 0.001476  , 0.00146165, 0.00159602,\n",
       "         0.00132995, 0.00148864, 0.00145779, 0.00144739, 0.00149684,\n",
       "         0.00130563, 0.001405  , 0.0014966 , 0.001475  , 0.00149565,\n",
       "         0.00137835, 0.00133696, 0.0014811 , 0.00151267, 0.00151639,\n",
       "         0.00130858, 0.00144224, 0.00143967, 0.00145659, 0.00152459,\n",
       "         0.0013092 , 0.00137072, 0.00156546, 0.00149689, 0.00160475,\n",
       "         0.0013896 , 0.00141983, 0.00142479, 0.00146809, 0.00157971,\n",
       "         0.00144124, 0.00147424, 0.00143757, 0.00146942, 0.00151429,\n",
       "         0.00130177, 0.00158367, 0.00141163, 0.00151944, 0.00156741,\n",
       "         0.00137959, 0.00138421, 0.00147367, 0.00155449, 0.00152164,\n",
       "         0.00132108, 0.00138259, 0.00148034, 0.00146365, 0.00149584,\n",
       "         0.00137305, 0.0016263 , 0.00150943, 0.00155067, 0.00157695,\n",
       "         0.00137668, 0.00145326, 0.00141692, 0.00147462, 0.00155368,\n",
       "         0.00132875, 0.0014246 , 0.00145063, 0.00150261, 0.00157084,\n",
       "         0.00144887, 0.00135384, 0.00143123, 0.00147767, 0.00156274,\n",
       "         0.00133834, 0.00155425, 0.00151262, 0.0015624 , 0.00158882,\n",
       "         0.00140362, 0.00150914, 0.00144219, 0.00154686, 0.00167937,\n",
       "         0.00134187, 0.00136037, 0.00143781, 0.00156651, 0.00151162,\n",
       "         0.00141249, 0.00138407, 0.00150652, 0.0016057 , 0.0016016 ,\n",
       "         0.00132484, 0.00135002, 0.00155158, 0.00147576, 0.00147634]),\n",
       "  'std_score_time': array([3.25870402e-04, 1.81632813e-04, 9.00891157e-05, 7.90173414e-05,\n",
       "         6.07046477e-05, 7.78535637e-05, 3.94692146e-05, 2.21528711e-05,\n",
       "         2.25998751e-04, 4.46509052e-05, 6.35870173e-05, 7.85709287e-05,\n",
       "         7.59175673e-05, 1.02878321e-04, 5.19858796e-05, 1.78662770e-04,\n",
       "         6.85157090e-05, 5.84600411e-05, 5.95469004e-05, 2.25430535e-05,\n",
       "         3.78046170e-05, 2.20890026e-04, 5.99352252e-05, 8.94152955e-05,\n",
       "         1.29622987e-04, 8.45250860e-05, 1.36945324e-04, 1.72524138e-05,\n",
       "         1.34762027e-04, 1.11558293e-04, 1.84129951e-04, 1.49652742e-04,\n",
       "         1.31329593e-04, 9.29221662e-05, 5.28693078e-05, 9.49264823e-05,\n",
       "         1.24662470e-04, 1.41028860e-04, 2.28948613e-04, 2.28709981e-04,\n",
       "         5.43609000e-05, 2.32423824e-04, 2.67855183e-05, 3.51538816e-04,\n",
       "         3.42876754e-05, 1.93323545e-04, 8.51206551e-05, 1.35985313e-04,\n",
       "         1.00269614e-04, 6.59822029e-05, 1.00897053e-04, 2.51117134e-05,\n",
       "         7.01622414e-05, 2.45590117e-05, 7.07269267e-05, 4.29321362e-05,\n",
       "         1.74096531e-04, 8.03773495e-05, 2.12208072e-05, 3.03634836e-05,\n",
       "         7.96959385e-05, 9.89652518e-05, 8.70649549e-05, 5.27815011e-05,\n",
       "         2.57140379e-05, 9.79944330e-05, 5.01932211e-05, 6.13254854e-05,\n",
       "         5.54763916e-05, 4.43510852e-05, 5.34390873e-05, 7.99740501e-05,\n",
       "         5.15109065e-05, 3.00663128e-05, 6.56903718e-05, 3.18466541e-05,\n",
       "         4.41274082e-06, 1.55983631e-04, 2.81352511e-05, 1.07203174e-04,\n",
       "         9.98363787e-05, 6.11189922e-05, 3.24428032e-05, 3.16993080e-05,\n",
       "         1.35508395e-04, 2.70265522e-04, 1.18415344e-04, 4.39902889e-05,\n",
       "         2.94696937e-05, 4.58422822e-05, 4.60709590e-05, 1.90763328e-04,\n",
       "         1.06766811e-05, 1.06449343e-04, 7.24361630e-05, 1.34868701e-04,\n",
       "         1.26720316e-05, 7.74693838e-05, 1.38659130e-04, 5.92609798e-05,\n",
       "         5.44785149e-05, 1.61273912e-05, 4.63057740e-05, 4.39870325e-05,\n",
       "         4.45770064e-05, 1.67341040e-04, 1.32206522e-04, 1.29184418e-04,\n",
       "         1.55348614e-04, 1.14748799e-04, 6.77889723e-05, 1.26607997e-04,\n",
       "         3.04048662e-05, 2.02282393e-05, 9.83759782e-05, 5.19405477e-05,\n",
       "         1.02379547e-04, 2.07933808e-05, 4.64150458e-05, 9.33152897e-05,\n",
       "         2.65404881e-04, 4.23947119e-05, 7.47311998e-05, 4.63927024e-05,\n",
       "         1.02868773e-04, 7.91546236e-05, 1.90390037e-04, 1.54412035e-04,\n",
       "         1.14290655e-04, 1.12171723e-04, 1.05627708e-04, 1.36514689e-04,\n",
       "         4.38109304e-05, 1.54727890e-04, 3.48407863e-04, 5.99461120e-05,\n",
       "         1.15325608e-05, 5.34480217e-05, 1.03426694e-04, 6.73169106e-05,\n",
       "         1.17878312e-04, 2.81977322e-05, 1.06010177e-04, 1.62495959e-04,\n",
       "         1.09512025e-04, 8.61410517e-05, 8.26126397e-06, 2.39866599e-04,\n",
       "         5.24400350e-05, 2.89096267e-05]),\n",
       "  'param_max_features': masked_array(data=[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                     9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                     9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                     13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                     13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                     13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_split': masked_array(data=[10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 30, 30, 30, 30,\n",
       "                     30, 40, 40, 40, 40, 40, 50, 50, 50, 50, 50, 60, 60, 60,\n",
       "                     60, 60, 70, 70, 70, 70, 70, 80, 80, 80, 80, 80, 90, 90,\n",
       "                     90, 90, 90, 100, 100, 100, 100, 100, 10, 10, 10, 10,\n",
       "                     10, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 40, 40, 40,\n",
       "                     40, 40, 50, 50, 50, 50, 50, 60, 60, 60, 60, 60, 70, 70,\n",
       "                     70, 70, 70, 80, 80, 80, 80, 80, 90, 90, 90, 90, 90,\n",
       "                     100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 20, 20,\n",
       "                     20, 20, 20, 30, 30, 30, 30, 30, 40, 40, 40, 40, 40, 50,\n",
       "                     50, 50, 50, 50, 60, 60, 60, 60, 60, 70, 70, 70, 70, 70,\n",
       "                     80, 80, 80, 80, 80, 90, 90, 90, 90, 90, 100, 100, 100,\n",
       "                     100, 100],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1,\n",
       "                     0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3,\n",
       "                     0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5,\n",
       "                     0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7,\n",
       "                     0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9,\n",
       "                     0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1,\n",
       "                     0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3,\n",
       "                     0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5,\n",
       "                     0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7,\n",
       "                     0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9,\n",
       "                     0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1,\n",
       "                     0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3,\n",
       "                     0.5, 0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9, 0.1, 0.3, 0.5,\n",
       "                     0.7, 0.9, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_features': 9, 'min_samples_split': 10, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 10, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 10, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 10, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 10, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 20, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 20, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 20, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 20, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 20, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 30, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 30, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 30, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 30, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 30, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 40, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 40, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 40, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 40, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 40, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 50, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 50, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 50, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 50, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 50, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 60, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 60, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 60, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 60, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 60, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 70, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 70, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 70, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 70, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 70, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 80, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 80, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 80, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 80, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 80, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 90, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 90, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 90, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 90, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 90, 'subsample': 0.9},\n",
       "   {'max_features': 9, 'min_samples_split': 100, 'subsample': 0.1},\n",
       "   {'max_features': 9, 'min_samples_split': 100, 'subsample': 0.3},\n",
       "   {'max_features': 9, 'min_samples_split': 100, 'subsample': 0.5},\n",
       "   {'max_features': 9, 'min_samples_split': 100, 'subsample': 0.7},\n",
       "   {'max_features': 9, 'min_samples_split': 100, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 10, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 10, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 10, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 10, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 10, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 20, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 20, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 20, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 20, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 20, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 30, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 30, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 30, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 30, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 30, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 40, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 40, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 40, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 40, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 40, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 50, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 50, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 50, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 50, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 50, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 60, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 60, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 60, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 60, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 60, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 70, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 70, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 70, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 70, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 70, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 80, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 80, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 80, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 80, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 80, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 90, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 90, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 90, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 90, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 90, 'subsample': 0.9},\n",
       "   {'max_features': 11, 'min_samples_split': 100, 'subsample': 0.1},\n",
       "   {'max_features': 11, 'min_samples_split': 100, 'subsample': 0.3},\n",
       "   {'max_features': 11, 'min_samples_split': 100, 'subsample': 0.5},\n",
       "   {'max_features': 11, 'min_samples_split': 100, 'subsample': 0.7},\n",
       "   {'max_features': 11, 'min_samples_split': 100, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 10, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 10, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 10, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 10, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 10, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 20, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 20, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 20, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 20, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 20, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 30, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 30, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 30, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 30, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 30, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 40, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 40, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 40, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 40, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 40, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 50, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 50, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 50, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 50, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 50, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 60, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 60, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 60, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 60, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 60, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 70, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 70, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 70, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 70, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 70, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 80, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 80, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 80, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 80, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 80, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 90, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 90, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 90, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 90, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 90, 'subsample': 0.9},\n",
       "   {'max_features': 13, 'min_samples_split': 100, 'subsample': 0.1},\n",
       "   {'max_features': 13, 'min_samples_split': 100, 'subsample': 0.3},\n",
       "   {'max_features': 13, 'min_samples_split': 100, 'subsample': 0.5},\n",
       "   {'max_features': 13, 'min_samples_split': 100, 'subsample': 0.7},\n",
       "   {'max_features': 13, 'min_samples_split': 100, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70287698, 0.71626984, 0.90707672, 0.91699735,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.70667989, 0.8015873 , 0.90674603, 0.9156746 ,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772,\n",
       "         0.5       , 0.73065476, 0.78042328, 0.89384921, 0.91236772]),\n",
       "  'split1_test_score': array([0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.75611772, 0.7729828 , 0.91402116, 0.92328042,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.77248677, 0.7650463 , 0.90542328, 0.91468254,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323,\n",
       "         0.5       , 0.73859127, 0.76190476, 0.91170635, 0.91501323]),\n",
       "  'split2_test_score': array([0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.64715608, 0.82126323, 0.93171296, 0.93171296,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.66815476, 0.79679233, 0.91881614, 0.92261905,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376,\n",
       "         0.5       , 0.6780754 , 0.8301918 , 0.91683201, 0.91286376]),\n",
       "  'split3_test_score': array([0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.71345899, 0.84358466, 0.93022487, 0.92791005,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.72172619, 0.81944444, 0.94444444, 0.93154762,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148,\n",
       "         0.5       , 0.73726852, 0.84292328, 0.91898148, 0.91898148]),\n",
       "  'split4_test_score': array([0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68552189, 0.75909091, 0.86632997, 0.9023569 ,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.68636364, 0.77626263, 0.89494949, 0.90538721,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101,\n",
       "         0.5       , 0.67676768, 0.77777778, 0.88686869, 0.91010101]),\n",
       "  'mean_test_score': array([0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.70102633, 0.78263829, 0.90987314, 0.92045154,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71108225, 0.7918266 , 0.91407588, 0.9179822 ,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544,\n",
       "         0.5       , 0.71227152, 0.79864418, 0.90564755, 0.91386544]),\n",
       "  'std_test_score': array([0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.0355962 , 0.04529641, 0.02371584, 0.01029368,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.03565661, 0.01919425, 0.01696545, 0.00872201,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696,\n",
       "         0.        , 0.02858468, 0.03185305, 0.01289528, 0.00299696]),\n",
       "  'rank_test_score': array([121, 111,  81,  41,   1, 121, 111,  81,  41,   1, 121, 111,  81,\n",
       "          41,   1, 121, 111,  81,  41,   1, 121, 111,  81,  41,   1, 121,\n",
       "         111,  81,  41,   1, 121, 111,  81,  41,   1, 121, 111,  81,  41,\n",
       "           1, 121, 111,  81,  41,   1, 121, 111,  81,  41,   1, 121, 101,\n",
       "          71,  21,  11, 121, 101,  71,  21,  11, 121, 101,  71,  21,  11,\n",
       "         121, 101,  71,  21,  11, 121, 101,  71,  21,  11, 121, 101,  71,\n",
       "          21,  11, 121, 101,  71,  21,  11, 121, 101,  71,  21,  11, 121,\n",
       "         101,  71,  21,  11, 121, 101,  71,  21,  11, 121,  91,  61,  51,\n",
       "          31, 121,  91,  61,  51,  31, 121,  91,  61,  51,  31, 121,  91,\n",
       "          61,  51,  31, 121,  91,  61,  51,  31, 121,  91,  61,  51,  31,\n",
       "         121,  91,  61,  51,  31, 121,  91,  61,  51,  31, 121,  91,  61,\n",
       "          51,  31, 121,  91,  61,  51,  31], dtype=int32)},\n",
       " {'max_features': 9, 'min_samples_split': 10, 'subsample': 0.9},\n",
       " 0.9204515392015391)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'max_features':range(9,15,2),'subsample':[0.1,0.3,0.5,0.7,0.9],'min_samples_split':range(10,101,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.5, min_samples_split=100,n_estimators = 65,\n",
    "                                  min_samples_leaf=60,max_depth=5,max_features=9, subsample=0.8,random_state=10), \n",
    "                       param_grid = param_test3, scoring='roc_auc',iid=False,cv=5)\n",
    "gsearch3.fit(x_train,y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9344\n",
      "AUC Score (Train): 0.983725\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=0.5,n_estimators = 65,max_features= 9,min_samples_leaf=60,max_depth=5,subsample=0.9,random_state=10)\n",
    "gbc.fit(x_train,y_train)\n",
    "movies_pred = gbc.predict(x_train)\n",
    "movies_predprob = gbc.predict_proba(x_train)[:,1]\n",
    "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_train, movies_pred))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, movies_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.83      0.82        70\n",
      "         1.0       0.82      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.81       138\n",
      "   macro avg       0.81      0.81      0.81       138\n",
      "weighted avg       0.81      0.81      0.81       138\n",
      "\n",
      "[[58 12]\n",
      " [14 54]]\n"
     ]
    }
   ],
   "source": [
    "predicitons_gbc = gbc.predict(x_test)\n",
    "print(classification_report(y_test,predicitons_gbc))\n",
    "print(confusion_matrix(y_test, predicitons_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.88        70\n",
      "         1.0       0.87      0.88      0.88        68\n",
      "\n",
      "    accuracy                           0.88       138\n",
      "   macro avg       0.88      0.88      0.88       138\n",
      "weighted avg       0.88      0.88      0.88       138\n",
      "\n",
      "[[61  9]\n",
      " [ 8 60]]\n"
     ]
    }
   ],
   "source": [
    "# the last step is voting.\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf= VotingClassifier(estimators=[('svm', svm),('xgb1', xgb1),('gbc',gbc)])\n",
    "voting_clf.fit(x_train,y_train)\n",
    "votingg_pred = voting_clf.predict(x_test)\n",
    "print(votingg_pred)\n",
    "print(classification_report(y_test, votingg_pred))\n",
    "print(confusion_matrix(y_test, votingg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
